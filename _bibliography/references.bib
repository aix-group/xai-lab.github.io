@InProceedings{Schloetterer2018_iv_query-crumbs-experts,
  author        = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Michael Granitzer},
  booktitle     = {Proc. International Conference on Information Visualization (IV)},
  title         = {QueryCrumbs for Experts: A Compact Visual Query Support System to Facilitate Insights into Search Engine Internals},
  year          = {2018},
  date-added    = {2018-05-17 07:32:42 +0000},
  date-modified = {2018-05-17 07:34:18 +0000},
  doi           = {10.1109/iV.2018.00024},
  file          = {Schloetterer2018_iv_QueryCrumbsforExperts_preprint.pdf},
}


@InProceedings{Boehm2015_nldb-ws_economics-tweet-detection,
  author     = {Alexander B\"{o}hm and Christin Seifert and J\"{o}rg Schl\"{o}tterer and Michael Granitzer},
  booktitle  = {Proceedings NLDB Workshop},
  title      = {Identifying Tweets from the Economic Domain},
  year       = {2015},
  editor     = {Babik, Wieslaw and Ohly, H. Peter and Weber, Karsten},
  bdsk-url-1 = {http://www.ergon-verlag.de/en/bibliotheks--informationswissenschaft/fortschritte-in-der-wissensorganisation/band-13.php},
  file       = {Submission:own/Boehm2015_isko-nldb_twitter-user-classification_submission.pdf:PDF;Publisher Version:own/Boehm2015_isko-nldb_twitter-user-classification_publisher-version.pdf:PDF;Presentation by Joerg Schloetterer:own/Boehm2015_isko-nldb_twitter-user-classification_slides.pdf:PDF;Presentation by Joerg Schloetterer:own/Boehm2015_isko-nldb_twitter-user-classification_slides.odp:OpenDocument presentation},
  owner      = {sech},
  timestamp  = {2015.06.06},
  url        = {http://www.ergon-verlag.de/en/bibliotheks--informationswissenschaft/fortschritte-in-der-wissensorganisation/band-13.php},
}

@InProceedings{Borst2015_emtacl_eexcess,
  author        = {Timo Borst and Tamara Pianos and Christin Seifert},
  booktitle     = {Emerging Technologies in Digital Libraries (emtacl)},
  title         = {EEXCESS - Toolbox for managing and disseminating digital library content},
  year          = {2015},
  date-modified = {2015-03-05 18:04:52 +0000},
  file          = {:own/Borst2015_emtacl_EEXCESS-toolbox.pdf:PDF},
  owner         = {sech},
  timestamp     = {2015.02.17},
}

@TechReport{EEXCESS-D75_test-beds-second-report,
  author      = {Gerhard Doppler and Atif Latif and Christopher Koska and Petr Knoth and Christin Seifert and Gordon McKenna},
  institution = {BIT Media},
  title       = {{D7.5 -- Second Evaluation Report Test Beds}},
  year        = {2016},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D75.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@InProceedings{Fritz2005_scia_building-detection-sift,
  author    = {Gerald Fritz and Christin Seifert and Manish Kumar and Lucas Paletta},
  booktitle = {Proc. 19th Scandinavian Conference on Image Analyssis, (SCIA)},
  title     = {{Building Detection from Mobile Phone Imagery Using Informative SIFT Descriptors}},
  year      = {2005},
  address   = {Joensuu, Finland},
  month     = {6},
  number    = {3540},
  pages     = {629--638},
  publisher = {Springer-Verlag},
  series    = {Lecture Notes in Computer Science, LNCS},
  abstract  = {We propose reliable outdoor object detection on mobile phone imagery from off-the-shelf devices. With the goal to provide both robust object detection and reduction of computational complexity for situated interpretation of urban imagery, we propose to apply the 'Informative Descriptor Approach' on SIFT features (i-SIFT descriptors). We learn an attentive matching of i-SIFT keypoints, resulting in a signi cant improvement of state-of-the-art SIFT descriptor based keypoint matching. In the online learning stage, rstly, standard SIFT responses are evaluated using an information theoretic quality criterion with respect to object semantics, rejecting features with insufficient conditional entropy measure, producing both sparse and discriminative object representations. Secondly, we learn a decision tree from the training data set that maps SIFT descriptors to entropy values. The key advantages of informative SIFT (i-SIFT) to standard SIFT encoding are argued from observations on performance complexity, and demonstrated in a typical outdoor mobile vision experiment on the MPG-20 reference database.},
  file      = {Fritz2005.pdf:own/Fritz2005.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2004f_mlearn_mobile-vision-for-ambient-learning,
  author    = {Gerald Fritz and Christin Seifert and Patrick Luley and Lucas Paletta and Alexander Almer},
  booktitle = {Proceedings of the International Conference on Mobile Learning ({MLEARN} 2004)},
  title     = {Mobile Vision for Ambient Learning in Urban Environments},
  year      = {2004},
  month     = {7},
  abstract  = {We describe a mobile vision system that is capable of automated object identification using images captured from a PDA or a camera phone. We present a solution for the enabling technology of outdoors vision based object recognition that will extend state-of-the-art location and context aware services towards object based awareness in urban environments. In the proposed application scenario, tourist pedestrians are equipped with GPS, W-LAN and a camera attached to a PDA or a camera phone. They are interested whether their field of view contains tourist sights that would point to more detailed information. Multimedia type data about related history, the architecture, or other related cultural context of historic or artistic relevance might be explored by a mobile user who is intending to learn within the urban environment. Ambient learning is in this way achieved by pointing the device towards the urban sight, capturing an image, and consequently getting information about the object on site and within the focus of attention, i.e., the user?s current field of view.},
  file      = {Fritz2004f.pdf:own/Fritz2004f.pdf:PDF},
  keywords  = {mobile vision, object recognition, location based services, learning in urban environments.},
  owner     = {sech},
  timestamp = {2007.11.04},
  username  = {sech},
}

@InProceedings{Fritz2006_icvs_mobile-vision-system-for-urban-object-detection,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta},
  booktitle = {Proc. {IEEE} 4th International Conference on Computer Vision Systems, {ICVS}},
  title     = {A Mobile Vision System for Urban Object Detection with Informative Local Descriptors},
  year      = {2006},
  address   = {New York, NY},
  month     = {1},
  abstract  = {We present a computer vision system for the detection and identification of urban objects from mobile phone imagery, e.g., for the application of tourist information services. Recognition is based on MAP decision making over weak object hypotheses from local descriptor responses in the mobile imagery. We present an improvement over the standard SIFT key detector [7] by selecting only informative (i-SIFT) keys for descriptor matching. Selection is applied first to reduce the complexity of the object model and second to accelerate detection by selective filtering. We present results on the MPG-20 mobile phone imagery with severe illumination, scale and viewpoint changes in the images, performing with 98\% accuracy in identification, efficient (100\%) background rejection, efficient (0\%) false alarm rate, and reliable quality of service under extreme illumination conditions, significantly improving standard SIFT based recognition in every sense, providing (important for mobile vision) runtimes which are 8 ( 24) times faster for the MPG-20 (ZuBuD) database.},
  file      = {Fritz2006.pdf:own/Fritz2006.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2005a_icra_object-recognition-informative-features,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta},
  booktitle = {Proc. {IEEE} International Conference on Robotics and Automation, {ICRA}},
  title     = {Urban Object Recognition from Informative Local Features},
  year      = {2005},
  address   = {Barcelona, Spain},
  month     = {4},
  pages     = {132--138},
  abstract  = {Autonomous mobile agents require object recognition for high level interpretation and localization in complex scenes. In urban environments, recognition of buildings might play a dominant role in robotic systems that need object based navigation, that take advantage of visual feedback and multimodal information for self-localization, or that enable association to related information from the identified semantics. We present a new method - the informative local features approach - based on an information theoretic saliency measure that is rapidly derived from a local Parzen window density estimation in feature subspace. From the learning of a decision tree based mapping to informative features, it enables attentive access to discriminative information and thereby significantly speeds up the recognition process. This approach is highly robust with respect to severe degrees of partial occlusion, noise, and tolerant to some changes in scale and illumination. We present performance evaluation on our publicly available reference object database (TSG-20) that demonstrates the efficiency of this approach, case wise even outperforming the SIFT feature approach [1]. Building recognition will be advantageous in various application domains, such as, mobile mapping, unmanned vehicle navigation, and systems for car driver assistance.},
  file      = {Fritz2005a.pdf:own/Fritz2005a.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2005b_wapcv_attentive-object-detection-saliency-measure,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta and Horst Bischof},
  booktitle = {Proc. 2nd International Workshop on Attention and Performance in Computational Vision},
  title     = {Attentive Object Detection Using an Information Theoretic Saliency Measure},
  year      = {2005},
  address   = {Berlin, Germany},
  editor    = {Lucas Paletta and John K. Tsotsos and Erich Rome and Glyn W. Humphreys},
  number    = {3368},
  pages     = {29--41},
  publisher = {Springer-Verlag},
  series    = {Lecture Notes in Computer Science, LNCS},
  abstract  = {A major goal of selective attention is to focus processing on relevant information to enable rapid and robust task performance. For the example of attentive visual object recognition, we investigate here the impact of top-down information on multi-stage processing, instead of integrating generic visual feature extraction into object specific interpretation. We discriminate between generic and specific task based filters that select task relevant information of different scope and specificity within a processing chain. Attention is applied by tuned early features to selectively respond to generic task related visual features, i.e., to information that is in general locally relevant for any kind of object search. The mapping from appearances to discriminative regions is then modeled using decision trees to accelerate processing. The focus of attention on discriminative patterns enables efficient recognition of specific objects, by means of a sparse object representation that enables selective, task relevant, and rapid object specific responses. In the experiments the performance in object recognition from single appearance patterns dramatically increased considering only discriminative patterns, and evaluation of complete image analysis under various degrees of partial occlusion and image noise resulted in highly robust recognition, even in the presence of severe occlusion and noise effects. In addition, we present performance evaluation on our public available reference object database (TSG-20).},
  file      = {Fritz2005b.pdf:own/Fritz2005b.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2005c_hacippr_informative-sift-for-attentive-object-detection,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta and Horst Bischof},
  booktitle = {Proc. Joint Hungarian-Austrian Conference on Image Processing and Pattern Recognition, {HACIPPR}},
  title     = {Learning Informative SIFT Descriptors for Attentive Object Detection},
  year      = {2005},
  address   = {Veszprem, Hungary},
  month     = {5},
  note      = {\textbf{Best Paper Award of AAPR 2005}},
  pages     = {95--102},
  abstract  = {With the emerging sensor technologies in mobile devices, such as camera phones, visual interpretation methodologies are challenged to provide solutions within the everydays outdoor urban environment. For this purpose, we propose to apply the 'Informative Descriptor Approach' on the SIFT descriptor [4], in order to de ne the informative SIFT (i-SIFT) descriptor. By attentive matching of i-SIFT keypoints, we provide an innovative method on object detection that signifantly improves SIFT based keypoint matching. i-SIFT tackles the SIFT bottlenecks, e.g., extensive nearest neighbor indexing, by (i) signifantly reducing the descriptor dimensionality, (ii) decreasing the size of object representation by one order of magnitude, and (iii) performing matching exclusively on attended descriptors, as required by resource sensitive devices. The key advantages of informative SIFT (i-SIFT) are demonstrated in a typical outdoor mobile vision experiment on the TSG-20 reference database, detecting buildings with high accuracy.},
  file      = {Fritz2005c.pdf:own/Fritz2005c.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2004b_wapcv-ws_attentive-object-detection,
  author    = {Fritz, Gerald and Seifert, Christin and Paletta, Lucas and Bischof, Horst},
  booktitle = {Proc. {ECCV} 2nd International Workshop on Attention and Performance in Computational Vision},
  title     = {Attentive Object Detection Using an Information Theoretic Saliency Measure},
  year      = {2004},
  address   = {Prague, Czech Republic},
  month     = {5},
  pages     = {136--143},
  abstract  = {A major goal of selective attention is to focus processing on relevant information to enable rapid and robust task performance. For the example of attentive visual object recognition, we investigate here the impact of top-down information on multi-stage processing, instead of integrating generic visual feature extraction into object specific interpretation. We discriminate between generic and specific task based filters that select task relevant information of different scope and specificity within a processing chain. Attention is applied by tuned early features to selectively respond to generic task related visual features, i.e., to information that is in general locally relevant for any kind of object search. The mapping from appearances to discriminative regions is then modeled using decision trees to accelerate processing. The focus of attention on discriminative patterns enables efficient recognition of specific objects, by means of a sparse object representation that enables selective, task relevant, and rapid object specific responses. In the experiments, the performance in object recognition from single appearance patterns dramatically increased considering only discriminative patterns, and evaluation of complete image analysis under various degrees of partial occlusion and image noise resulted in highly robust recognition, even in the presence of severe occlusion and noise effects. Finally, preliminary results on attention for both generic and specific object detection demonstrated successful indexing to relevant object locations within a cluttered environment.},
  file      = {Fritz2004b.pdf:own/Fritz2004b.pdf:PDF},
  owner     = {sech},
  timestamp = {2012-07-13 12:18:09},
  username  = {sech},
}

@InProceedings{Fritz2004c_ecovision-ws_entropy-based-saliency-maps,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta and Horst Bischof},
  booktitle = {Proc. Early Cognitive Vision Workshop, (ECOVISION)},
  title     = {Entropy based Saliency Maps for Object Recognition},
  year      = {2004},
  address   = {Isle of Skye, UK},
  month     = {5},
  abstract  = {Object identification from local information has recently been investigated with respect to its potential for integration and robust recognition. In contrast to existing approaches, we do not use generic interest operators but select regions of interest from top-down information, i.e., with respect to object recognition. Discriminative regions are determined from the information content in the local appearance patterns (imagettes) and consequently enable to model sparse object representation and attention based recognition using decision trees. Recognition performance from single imagettes dramatically increased considering only discriminative patterns. Evaluation of complete image analysis under various degrees of partial occlusion and image noise resulted in highly robust recognition even in the presence of severe occlusion and noise effects.},
  file      = {Fritz2004c.pdf:own/Fritz2004c.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2004d_aaai_rapid-object-detection-from-discriminative-regions-of-interest,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta and Horst Bischof},
  booktitle = {Proc. 19th International Conference on Artificial Intelligence, {AAAI}},
  title     = {Rapid Object Recognition from Discriminative Regions of Interest},
  year      = {2004},
  address   = {San Jose, CA},
  month     = {7},
  pages     = {444--449},
  abstract  = {Object recognition and detection represent a relevant component in cognitive computer vision systems, such as in robot vision, intelligent video surveillance systems, or multi-modal interfaces. Object identification from local information has recently been investigated with respect to its potential for robust recognition, e.g., in case of partial object occlusions, scale variation, noise, and background clutter in detection tasks. This work contributes to this research by a thorough analysis of the discriminative power of local appearance patterns and by proposing to exploit local information content to model object representation and recognition. We identify discriminative regions in the object views from a posterior entropy measure, and then derive object models from selected discriminative local patterns. For recognition, we determine rapid attentive search for locations of high information content from learned decision trees. The recognition system is evaluated by various degrees of partial occlusion and Gaussian image noise, resulting in highly robust recognition even in the presence of severe occlusion effects.},
  file      = {Fritz2004d.pdf:own/Fritz2004d.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Fritz2004e_ecai_focus-attention-for-object-detection,
  author    = {Gerald Fritz and Christin Seifert and Lucas Paletta and Horst Bischof},
  booktitle = {Proc. European Conference on Artificial Intelligence (ECAI)},
  title     = {Learning to Focus Attention on Discriminative Regions for Object Detection},
  year      = {2004},
  address   = {Valencia, Spain},
  month     = {8},
  pages     = {932--936},
  abstract  = {A major task of visual attention is to focus processing on regions of interest to enable rapid and robust object search. Instead of integrating generic feature extraction into object specific interpretation we strictly pursue a top-down approach. Early features are tuned to selectively respond to task related visual features, i.e., locally discriminative information that is useful in object recognition. In this work we determine discriminative regions from the information content in the local appearance patterns. A rapid mapping from appearances to discriminative regions is estimated using decision trees. The focus of attention on discriminative patterns enables then efficient detection of a searched object, but also the definition of sparse object representations to respond only to task relevant information. In the experiments, the performance in object recognition from single imagettes dramatically increased considering only discriminative patterns. Evaluation of complete image analysis under various degrees of partial occlusion and image noise resulted in highly robust recognition even in the presence of severe occlusion and noise effects. Finally, preliminary results on attentive object detection in cluttered environments demonstrated successful indexing to relevant locations.},
  file      = {Fritz2004e.pdf:own/Fritz2004e.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Granitzer2008_icdim_ml-for-context-extraction,
  author    = {Michael Granitzer and Mark Kr\"{o}ll and Christin Seifert and Andreas S. Rath and Nicolas Weber and Olivia Dietzel and Stefanie Lindstaedt},
  booktitle = {Proceedings of 2008 International Conference on Digital Information Management},
  title     = {Analysis of Machine Learning Techniques for Context Extraction},
  year      = {2008},
  address   = {London, UK},
  editor    = {IEEE Computer Society Press},
  month     = {11},
  abstract  = {'Context is key' conveys the importance of capturing the digital environment of a knowledge worker. Knowing the user's context offers various possibilities for support, like for example enhancing information delivery or providing work guidance. Hence, user interactions have to be aggregated and mapped to predefined task categories. Without machine learning tools, such an assignment has to be done manually. The identification of suitable machine learning algorithms is necessary in order to ensure accurate and timely classification of the user's context without inducing additional workload. This paper provides a methodology for recording user interactions and an analysis of supervised classification models, feature types and feature selection for automatically detecting the current task and context of a user. Our analysis is based on a real world data set and shows the applicability of machine learning techniques.},
  file      = {:own/Granitzer2008_icdim_taskclass_dionypos.pdf:PDF},
  owner     = {sech},
  timestamp = {2008.10.21},
}

@Article{Granitzer2009a_jdim_machine-learning-based-work-task-classification,
  author     = {Michael Granitzer and Andreas S. Rath and Mark Kr\"{o}ll and Christin Seifert and Doris Ipsmiller and Didier Devaurs and Nicolas Weber and Stefanie Lindstaedt},
  journal    = {Journal of Digital Information Management (JDIM)},
  title      = {Machine Learning based Work Task Classification},
  year       = {2009},
  number     = {5},
  volume     = {7},
  bdsk-url-1 = {http://www.dirf.org/jdim/v7i5.asp},
  file       = {:own/Granitzer2009a_jdim_task-classification.pdf:PDF},
  owner      = {sech},
  timestamp  = {2009.10.27},
  url        = {http://www.dirf.org/jdim/v7i5.asp},
}

@Article{Granitzer2016_dlib_eexcess-project,
  author    = {Michael Granitzer and Christin Seifert},
  journal   = {D-Lib Magazine},
  title     = {Taking Cultural and Scientific Content to Users through the EEXCESS Project},
  year      = {2016},
  month     = {3},
  number    = {3/4},
  volume    = {22},
  doi       = {10.1045/march2016-content},
  owner     = {sech},
  timestamp = {2016.03.17},
  url       = {http://www.dlib.org/dlib/march16/03contents.html},
}

@InProceedings{Granitzer2013_umap-poster_eexcess-project,
  author     = {Michael Granitzer and Christin Seifert and Silvia Russegger and Klaus Tochtermann},
  booktitle  = {UMAP Extended Proceedings},
  title      = {Unfolding Cultural, Educational and Scientific Long-Tail Content in the Web},
  year       = {2013},
  editor     = {Shlomo Berkovsky and Eelco Herder and Pasquale Lops and Olga C. Santos},
  month      = {6},
  volume     = {997},
  bdsk-url-1 = {http://ceur-ws.org/Vol-997/umap2013_project_1.pdf},
  file       = {:own/Granitzer2013_umap1013_EEXCESS-project-intro.pdf:PDF;Poster Madness Presentation:own/Granitzer2013_umap1013_EEXCESS-project-intro_poster-madness.pdf:PDF;Poster:own/Granitzer2013_umap1013_EEXCESS-project-intro_poster.pdf:PDF},
  owner      = {sech},
  timestamp  = {2013.06.12},
  url        = {http://ceur-ws.org/Vol-997/umap2013_project_1.pdf},
}

@TechReport{EEXCESS-D13_architecture-requirements,
  author      = {Michael Granitzer and Christin Seifert and J\"{o}rg Schl\"{o}tterer and Thomas Orgel and Thomas Cerques and Roman Kern and Vedran Sabol and Louis Gantner},
  institution = {University of Passau},
  title       = {{D1.3 -- Third Conceptual Architecture and Requirements Definition}},
  year        = {2016},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D13.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@TechReport{EEXCESS-D12_second-architecture-and-requirements,
  author      = {Michael Granitzer and Christin Seifert and J\"{o}rg Schl\"{o}tterer and Thomas Orgel and Silvia Russegger and Kris Jack and Nils Witt and Timo Borst and Gordon McKenna and Louis Gantner and Gerhard Doppler and Vedran Sabol and Hermann Ziak and Christopher Koska and Thomas Cerques},
  institution = {University of Passau},
  title       = {{D1.2 -- Second Conceptual Architecture and Requirements Definition}},
  year        = {2015},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D12.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@InProceedings{Granitzer2015_tir_ws-preface,
  author     = {Michael Granitzer and Christin Seifert and Benno Stein},
  booktitle  = {26th International Workshop on Database and Expert Systems Applications (DEXA)},
  title      = {TIR 2015 Workshop Preface},
  year       = {2015},
  bdsk-url-1 = {https://www.computer.org/csdl/proceedings/dexa/2015/7581/00/index.html},
  owner      = {sech},
  timestamp  = {2016.03.14},
  url        = {https://www.computer.org/csdl/proceedings/dexa/2015/7581/00/index.html},
}

@TechReport{EEXCESS-D11_first-conceptual-architecture-and-requirements,
  author      = {Michael Granitzer and Christin Seifert and {Work Package Leader}},
  institution = {University of Passau},
  title       = {{D1.1 -- First Conceptual Architecture and Requirements Definition}},
  year        = {2013},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D11.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@InProceedings{Granitzer2009_inex_context-based-wikipedia-linking,
  author    = {Michael Granitzer and Christin Seifert and Mario Zechner},
  booktitle = {Advances in Focused Retrieval, International Workshop of the Initiative for the Evaluation of XML Retrieval (INEX2008)},
  title     = {Context based Wikipedia Linking},
  year      = {2009},
  editor    = {Shlomo Geva and Jaap Kamps and Andrew Trotman},
  publisher = {Springer},
  file      = {:own/Granitzer2009_inex-postproceedigns_wikipedia_linking.pdf:PDF},
  owner     = {sech},
  timestamp = {2009.04.17},
}

@InProceedings{Granitzer2008b_inex_context-resolution-wikipedia-linking,
  author    = {Michael Granitzer and Christin Seifert and Mario Zechner},
  booktitle = {INEX 2008 pre-proceedings},
  title     = {Context Resolution Strategies for Automatic Wikipedia Learning},
  year      = {2008},
  address   = {Dagstuhl, Germany},
  editor    = {Shlomo Geva and Jaap Kamps and Andrew Trotman},
  month     = dec,
  pages     = {292--304},
  abstract  = {Automatically linking Wikipedia pages is done mostly by two strategies: (i) a content based strategy based on word similarities or (ii) a structural similarity exploiting link characteristics. In our approach we focus on a content based strategy by finding anchors using the title of candidate Wikipedia pages and resolving matching links by taking the context of the link anchor, i.e. its surrounding text, into account. Bestentry-points are estimated on a combination of title and content based similarity. Our goal was to evaluate syntactic title matching properties and the influence of the context around anchors for disambiguation and best-entry-point detection. Results show, that the whole Wikipedia page provides the best context for resolving links and that simple inverse document frequency based scoring of anchor texts is also capable of achieving high accuracy.},
  file      = {:own/Granitzer2008b_inex-wikipedia_linking.pdf:PDF},
  owner     = {sech},
  timestamp = {2009.01.07},
}

@InProceedings{Granitzer2008a_iadiswww_eval-linking-wikipedia,
  author    = {Michael Granitzer and Mario Zechner and Christin Seifert and Josef Kolbitsch and Peter Kemper and Ronald {In`t Velt}},
  booktitle = {Proceedings of the IADIS WWW/Internet Conference 2008},
  title     = {Evaluation of Automatic Linking Strategies for Wikipedia Pages},
  year      = {2008},
  address   = {Freiburg, Germany},
  month     = oct,
  abstract  = {Wikipedia contains an enormous amount of human knowledge. The wide range of covered topics is hierarchically organized in categories and strongly inter-linked. Its structure, its size and the fact that it is generated by humans are the reasons for the attention Wikipedia receives from researchers in different fields. Especially the link structure of Wikipedia is of huge importance not only for humans browsing the collection, but also as a resource for bootstrapping machine intelligence and the semantic web. Motivated by the fact that manual maintenance and creation of hyperlinks is labor intensive, this paper explores properties for automatic link creation between Wikipedia pages in this paper. Focusing on ad-hoc linking approaches we evaluate linking strategies on the word as well as on the document level using a standard test data set. As it is shown, rather simple approaches yield to reliable results and may be applicable in different application scenarios. Disambiguation strategies based on standard IR techniques help to boost accuracy delivering reasonable results.},
  file      = {:own/Granitzer2008a_www_wikipedia_linking.pdf:PDF},
  owner     = {sech},
  timestamp = {2008.10.21},
}

@InProceedings{Hofler2014_www-ws_linked-data-query-wizard,
  author     = {Patrick H{\"{o}}fler and Michael Granitzer and Eduardo E. Veas and Christin Seifert},
  booktitle  = {Proc. Workshop on Linked Data on the Web at World Wide Web Conference {(WWW}},
  title      = {Linked Data Query Wizard: {A} Novel Interface for Accessing {SPARQL} Endpoints},
  year       = {2014},
  address    = {Seoul, Korea},
  editor     = {Christian Bizer and Tom Heath and S\"{o}ren Auer and Tim Berners-Lee},
  bdsk-url-1 = {http://ceur-ws.org/Vol-1184/ldow2014_paper_06.pdf},
  biburl     = {http://dblp.uni-trier.de/rec/bib/conf/www/HoflerGVS14},
  file       = {:own/Hoefler2014_ldow_linked-data-query-wizard.pdf:PDF},
  timestamp  = {Fri, 15 Aug 2014 10:33:04 +0200},
  url        = {http://ceur-ws.org/Vol-1184/ldow2014_paper_06.pdf},
}

@InCollection{Holzinger2014_lncs_biomedical-text-mining-soa,
  author     = {Holzinger, Andreas and Schantl, Johannes and Schroettner, Miriam and Seifert, Christin and Verspoor, Karin},
  booktitle  = {Interactive Knowledge Discovery and Data Mining in Biomedical Informatics},
  publisher  = {Springer Berlin Heidelberg},
  title      = {Biomedical Text Mining: State-of-the-Art, Open Problems and Future Challenges},
  year       = {2014},
  editor     = {Holzinger, Andreas and Jurisica, Igor},
  isbn       = {978-3-662-43967-8},
  pages      = {271-300},
  series     = {Lecture Notes in Computer Science},
  volume     = {8401},
  doi        = {10.1007/978-3-662-43968-5_16},
  file       = {:own/Holzinger2014_lncs8401_biomedical-text-mining.pdf:PDF},
  keywords   = {Text Mining; Natural Language Processing; Unstructured Information; Big Data; Knowledge Discovery; Statistical Models; Text Classification; LSA; PLSA; LDA; hLDA; PCA; SVM},
  language   = {English},
}

@InProceedings{Jurgovsky2016_ecir_memory-efficiency-robustness-word-embeddings,
  author     = {Johannes Jurgovsky and Michael Granitzer and Christin Seifert},
  booktitle  = {Proc. of European Conference on Information Retrieval (ECIR)},
  title      = {Evaluating Memory Efficiency and Robustness of Word Embeddings},
  year       = {2016},
  pages      = {200-211},
  volume     = {9626},
  addendum   = {\textit{Honorable Mention}},
  doi        = {10.1007/978-3-319-30671-1_15},
  file       = {:own/Jurgovsky2016_ecir_memory-effiecient-embeddings.pdf:PDF},
  owner      = {sech},
  timestamp  = {2016.01.12},
}

@Article{Kern2011_ijdl_german-encyclopedia-alignment,
  author      = {Roman Kern and Christin Seifert and Michael Granitzer},
  journal     = {International Journal on Digital Libraries},
  title       = {{A Hybrid System for German Encyclopedia Alignment}},
  year        = {2011},
  issn        = {1432-5012},
  pages       = {1-15},
  abstract    = {Collaboratively created on-line encyclopedias have become increasingly popular. Especially in terms of completeness they have begun to surpass their printed counterparts. Two German publishers of traditional encyclopedias have reacted to this challenge and started an initiative to merge their corpora to create a single, more complete encyclopedia. The crucial step in this merging process is the alignment of articles. We have developed a two-step hybrid system to provide high-accurate alignments with low manual effort. First, we apply an information retrieval based, automatic alignment algorithm. Second, the articles with a low confidence score are revised using a manual alignment scheme carefully designed for quality assurance. Our evaluation shows that a combination of weighting and ranking techniques utilizing different facets of the encyclopedia articles allow to effectively reduce the number of necessary manual alignments. Further, the setup of the manual alignment turned out to be robust against inter-indexer inconsistencies. As a result, the developed system empowered us to align four encyclopedias with high accuracy and low effort.},
  affiliation = {Graz University of Technology, Knowledge Management Institute, Inffeldgasse 21a, 8010 Graz, Austria},
  doi         = {10.1007/s00799-011-0069-5},
  file        = {:own/Kern2011_ijdl_encyclopedia-alignment.pdf:PDF},
  keyword     = {Computer Science},
  owner       = {sech},
  publisher   = {Springer Berlin / Heidelberg},
  timestamp   = {2011.09.27},
}

@InProceedings{Kern2011a_challenge_classifier-for-authorship-identification,
  author    = {Roman Kern and Christin Seifert and Mario Zechner and Michael Granitzer},
  booktitle = {3rd International Competition on Plagiarism Detection},
  title     = {Vote/Veto Meta-Classifier for Authorship Identification},
  year      = {2011},
  file      = {:own/Kern2011a_pan_authorship-attribution.pdf:PDF},
  owner     = {sech},
  timestamp = {2011.09.27},
}

@InProceedings{Kienreich2008_icadwit_apalabs,
  author    = {Wolfgang Kienreich and Elisabeth Lex and Christin Seifert},
  booktitle = {Proceedings International Conference on the Applications of Digital Information and Web Technologies (ICADIWT08)},
  title     = {{APA} Labs: An Experimental Web-Based Platform for the Retrieval and Analysis of News Articles},
  year      = {2008},
  address   = {Ostrava, Czech Republic},
  month     = aug,
  pages     = {58--62},
  publisher = {IEEE Computer Society},
  abstract  = {In this paper, we present APA Labs, an experimental, web-based platform supporting retrieval and analysis in the news archives of the Austrian Press Agency. APA Labs has been designed as a combination of a rich internet application with a modular system of interactive visualizations backed by server-side entity extraction and three-dimensional rendering capability. This paper outlines concepts and implementation details of APA Labs and presents several visualization modules based on research results from the field of Information and Knowledge visualization.},
  file      = {:own/Kienreich2008_icadiwt_apalabs.pdf:PDF},
  owner     = {sech},
  timestamp = {2008.08.07},
}

@InProceedings{Kienreich2012_eurova_visualizing-feature-class-matrices,
  author    = {Wolfgang Kienreich and Christin Seifert},
  booktitle = {Procedings of Workshop on Visual Analytics (EuroVA)},
  title     = {Visual Exploration of Feature-Class Matrices for Classification Problems},
  year      = {2012},
  address   = {Vienna},
  month     = {6},
  abstract  = {When a classification algorithm does not work on a data set, it is a non-trivial problem to figure out what went wrong on a technical level. It is even more challenging to communicate findings to domain experts who can interpret the data set but do not understand the algorithms. We propose a method for the interactive visual exploration of the feature-class matrix used to represent data sets for classification purposes. This method combines a novel matrix reordering algorithm revealing patterns of interest with an interactive visualization application. It facilitates the investigation of feature-class matrices and the identification of reasons for failure or success of a classifier on the feature level. We discuss results obtained by applying the method to the Reuters text collection.},
  file      = {:own/Kienreich2012_eurova_feature-class-matrix.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.05.07},
}

@InProceedings{Kienreich2010_iv_edge-bundling-for-media-analysis,
  author    = {Wolfgang Kienreich and Christin Seifert},
  booktitle = {Proceedings of the 14 International Conference on Information Visualization},
  title     = {An Application of Edge Bundling Techniques to the Visualization of Media Analysis Results},
  year      = {2010},
  publisher = {IEEE Computer Society Press},
  series    = {IV},
  abstract  = {The advent of consumer-generated and social media has led to a continuous expansion and diversification of the media landscape. Media consumers frequently find themselves assuming the role of media analysts in order to satisfy personal information needs. We propose to employ Knowledge Visualization methods in support of complex media analysis tasks. In this paper, we describe an approach which depicts semantic relationships between key political actors using node-link diagrams. Our contribution comprises a force-directed edge bundling algorithm which accounts for semantic properties of edges, a technical evaluation of the algorithm and a report on a real-world application of the approach. The resulting visualization fosters the identification of high-level edge patterns which indicate strong semantic relationships. It has been published by the Austrian Press Agency APA in 2009.},
  file      = {:own/Kienreich2010_iv_edge-bundling-apa.pdf:PDF},
  keywords  = {knowledge visualization; media analysis; edge bundling; layout quality evaluation},
  owner     = {sech},
  timestamp = {2010.07.14},
}

@InProceedings{Kienreich2009_irf_visualization-hierarchical-knowledge-repositories,
  author     = {Wolfgang Kienreich and Christin Seifert},
  booktitle  = {3rd International Conference on Integrity, Reliabilility \& Failure (IRF)},
  title      = {Scalable, interactive visualization of hierarchical knowledge repositories},
  year       = {2009},
  address    = {Porto, Portugal},
  abstract   = {Spatial tesselations based on Voronoi diagrams have been extensively used in Information Visualization and Visual Analytics to represent hierarchical knowledge repositories. This paper introduces a visualization framework which combines Voronoi diagrams and level of detail techniques to address precision, performance and usability issues identified in existing systems. The framework facilitates the interactive visualization of very large repositories organized into a hierarchy of unlimited depth using two or three visual dimensions.},
  bdsk-url-1 = {http://paginas.fe.up.pt/clme/IRF2009/PROCEEDINGS/PAPERS/A0260.pdf},
  file       = {:own/Kienreich2009_irf_hiearchical-document-repos.pdf:PDF},
  owner      = {sech},
  timestamp  = {2011.06.08},
  url        = {http://paginas.fe.up.pt/clme/IRF2009/PROCEEDINGS/PAPERS/A0260.pdf},
}

@InProceedings{Kienreich2012a_eurova_graphvis-hierarchical-edge-bundling,
  author    = {Wolfgang Kienreich and Ralph Wozelka and Vedran Sabol and Christin Seifert},
  booktitle = {Proceedings of Workshop on Visual Analytics (EuroVA)},
  title     = {Graph Visualization Using Hierachical Edge Bundling},
  year      = {2012},
  address   = {Vienna},
  month     = jun,
  file      = {:own/Kienreich2012a_eurovis_graphvis.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.05.07},
}

@InProceedings{Kump2012_lak_visualizing-evidence-in-open-learner-model,
  author    = {Barbara Kump and Christin Seifert and Guenter Beham and Stefanie Lindstaedt and Tobias Ley},
  booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledg (LAK)},
  title     = {Seeing What the System Thinks You Know - Visualizing Evidence in an Open Learner Model},
  year      = {2012},
  file      = {:own/Kump2012_lak_myexperiences.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.01.30},
}

@InProceedings{Kump2010_umap_visualizing-evidence-in-open-learner-model,
  author    = {Barbara Kump and Christin Seifert and G\"{u}nter Beham and Stefanie Lindstaedt and Tobias Ley},
  booktitle = {Adjunct Proceedings International Conference on User Modeling, Adaptation, and Personalization (UMAP 2010)},
  title     = {MyExperiences: Visualizing Evidence in an Open Learner Model},
  year      = {2010},
  address   = {Big Island, HI, USA},
  note      = {Poster},
  abstract  = {When inferring a user's knowledge state from naturally occurring interactions in adaptive learning systems, one has to makes complex assumptions that may be hard to understand for users. We suggest MyExperiences, an open learner model designed for these specific requirements. MyExperiences is based on some of the key design principles of information visualization to help users understand the complex information in the learner model. It further allows users to edit their learner models in order to improve the accuracy of the information represented there.},
  file      = {:own/Kump2010_umap_AposdleMyExperiences.pdf:PDF},
  owner     = {sech},
  timestamp = {2011.02.03},
}

@Article{Lex2010_ijcir_efficient-cross-domain-classification-weblogs,
  author     = {Elisabeth Lex and Christin Seifert and Michael Granitzer and Andreas Juffinger},
  journal    = {International Journal of Computational Intelligence Research},
  title      = {Efficient Cross-Domain Classification of Weblogs},
  year       = {2010},
  number     = {1},
  pages      = {69--76},
  volume     = {1},
  abstract   = {Text classification is one of the core applications in data mining due to the huge amount of uncategorized textual data available. Training a text classifier results in a classification model that reflects the characteristics of the domain it was learned on. However, if no training data is available, labeled data from a related but different domain might be exploited to perform cross-domain classification. In our work, we aim to accurately classify unlabeled weblogs into commonly agreed upon newspaper categories using labeled data from the news domain. The labeled news and the unlabeled blog corpus are highly dynamic and hourly growing with a topic drift, so the classification needs to be efficient. Our approach is to apply a fast novel centroid-based text classification algorithm, the Class-Feature-Centroid Classifier (CFC), to perform efficient cross-domain classification. Experiments showed that this algorithm achieves a comparable accuracy than k-Nearest Neighbour (k-NN) and Support Vector Machines (SVM), yet at linear time cost for training and classification. We investigate the classifier performance and generalization ability using a special visualization of classifiers. The benefit of our approach is that the linear time complexity enables us to efficiently generate an accurate classifier, reflecting the topic drift, several times per day on a huge dataset.},
  bdsk-url-1 = {http://www.infonomics-society.org/IJICR/Contents%20Page%20Volume%201%20Issue%201.pdf},
  file       = {:own/Lex2010_ijcir_cross-domain-classification-weblogs.pdf:PDF},
  owner      = {sech},
  timestamp  = {2010.04.29},
}

@InProceedings{Lex2009_icitst_cross-domain-classification,
  author    = {Elisabeth Lex and Christin Seifert and Michael Granitzer and Andreas Juffinger},
  booktitle = {Proceedings of the 4th International Conference for Internet Technology and Secured Transactions (ICITST)},
  title     = {Cross-Domain Classification: Trade-Off between Complexity and Accuracy},
  year      = {2009},
  abstract  = {Text classification is one of the core applications in data mining due to the huge amount of not categorized digital data available. Training a text classifier generates a model that reflects the characteristics of the domain. However, if no training data is available, labeled data from a related but different domain might be exploited to perform crossdomain classification. In our work, we aim to accurately classify unlabeled blogs into commonly agreed newspaper categories using labeled data from the news domain. The labeled news and the unlabeled blog corpus are highly dynamic and hourly growing with a topic drift, so a trade-off between accuracy and performance is required. Our approach is to apply a fast novel centroid-based algorithm, the Class-Feature-Centroid Classifier (CFC), to perform efficient cross-domain classification. Experiments showed that this algorithm achieves a comparable accuracy than k-NN and is slightly better than Support Vector Machines (SVM), yet at linear time cost for training and classification. The benefit of this approach is that the linear time complexity enables us to efficiently generate an accurate classifier, reflecting the topic drift, several times per day on a huge dataset.},
  file      = {:own/Lex2009_icitst_crossdomainclasswithvis.pdf:PDF},
  owner     = {sech},
  timestamp = {2009.07.30},
}

@InProceedings{Lex2009a_iadiswww_automated-blog-classification,
  author    = {Elisabeth Lex and Christin Seifert and Michael Granitzer and Andreas Juffinger},
  booktitle = {Proc. of IADIS International Conference WWW/Internet},
  title     = {Automated Blog Classification: A Cross-Domain Approach},
  year      = {2009},
  file      = {:own/Lex2009_icitst_crossdomainclasswithvis.pdf:PDF},
  owner     = {sech},
  timestamp = {2009.09.28},
}

@Article{Lex2008_jdim_apalabs-framwork,
  author     = {Elisabeth Lex and Christin Seifert and Wolfgang Kienreich and Michael Granitzer},
  journal    = {Journal of Digital Information Management (JDIM)},
  title      = {A Generic Framework for Visualizing the News Article Domain and its Application to Real-World Data},
  year       = {2008},
  issn       = {0972-7272},
  month      = oct,
  number     = {6},
  volume     = {6},
  abstract   = {In this work we present APA Labs, a generic framework for visualizing the news article domain. APA Labs is a web-based platform enabling retrieval and analysis of news repositories provided by the Austrian Press Agency. APA Labs is designed as a rich internet application combined with a modular system of interactive visualizations. News articles are analyzed using domain specific named entity extraction methods combined with language specific heuristics. The proposed methods were subject to an evaluation procedure outlined in this contribution. This article illustrates the domain, the underlying concepts and implementation details. Several visualization modules are presented and an outlook on planned modules is given. Being online for around six months the community feedback as well as the easy integration of new modules shows the success of the underlying concept and the platform itself.},
  bdsk-url-1 = {http://www.dirf.org/jdim/v6i6.asp},
  file       = {:own/Lex2008_jdim_apalabs.pdf:PDF},
  owner      = {sech},
  timestamp  = {2009.02.16},
  url        = {http://www.dirf.org/jdim/v6i6.asp},
}

@InProceedings{Luley2005b_ws_mobile-sensor-system-for-object-and-location-awareness,
  author    = {Patrick Luley and Alexander Almer and Christin Seifert and Gerald Fritz and Lucas Paletta},
  booktitle = {Proc 2nd {IEEE} International Workshop on Mobile Commerce and Service},
  title     = {A Multi-Sensor System for Mobile Services with Visual Enhanced Object and Location Awareness},
  year      = {2005},
  address   = {Munich, Germany},
  month     = {7},
  pages     = {52--58},
  abstract  = {We describe a system which includes a multi-sensor object awareness and positioning solution to enable stable location awareness for a mobile service in urban areas. The system offers technology of outdoors vision based object recognition that will extend state-of-the-art location and context aware services towards object based awareness in urban environments. In the proposed application scenario, tourist pedestrians are equipped with a GPRS or UMTS capable camera-phone. They are interested whether their field of view contains tourist sights that would point to more detailed information. Multimedia type data about related history might be explored by a mobile user who is intending to learn within the urban environment. Ambient learning is in this way achieved by pointing the device towards the urban sight, capturing an image, and consequently getting information about the object on site and within the focus of attention, i.e., the user's current field of view. The described mobile system offers multiple opportunities for application in both mobile business and commerce, and is currently developed towards an industrial prototype.},
  file      = {:own/Luley2005b.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@TechReport{EEXCESS-D63_second-security-proxy,
  author      = {Sonia Ben Mokhtar and Nadia Bennani and Lionel Brunie and Sylvie Calabretto and Thomas Cerqueus and El\"{o}d Egyed-{\~A}{\^A}-{\~A}{\^a}{\"\i}Zsigmond and Omar Hasan and Albin Petit and Pierre-{\~A}{\^A}-{\~A}{\^a}{\"\i}\'{E}douard Portier and Michael Granitzer and Christin Seifert and J\"{o}rg Schl\"{o}tterer},
  institution = {INSA},
  title       = {{D6.3 -- Second Security Proxy Prototype and Reputation Protocols}},
  year        = {2014},
  address     = {Lyon},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D63.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@TechReport{EEXCESS-D62_first-security-proxy,
  author      = {Sonia Ben Mokhtar and Nadia Bennani and Lionel Brunie and Thomas Cerqueus and El\"{o}d Egyed--Zsigmond and Omar Hasan and Albin Petit and Pierre--\'{E}douard Portier and Michael Granitzer and Christin Seifert and J\"{o}rg Schl\"{o}tterer},
  institution = {INSA},
  title       = {{D6.2 -- First Security Proxy Prototype and Reputation Protocols}},
  year        = {2014},
  address     = {Lyon},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D62.pdf:PDF},
  owner       = {sech},
  timestamp   = {2014.08.29},
}

@TechReport{EEXCESS-D61_policy-model-for-privacy-preservation,
  author      = {Sonia Ben Mokhtar and Nadia Bennani and Lionel Brunie and Thomas Cerqueus and El\"{o}d Egyed- Zsigmond and Omar Hasan and Albin Petit and Pierre-\'{E}douard Portier and Michael Granitzer and Christin Seifert and J\"{o}rg Schl\"{o}tterer},
  institution = {INSA},
  title       = {{D6.1 -- Policy Model for Privacy Preservation and Feasibility Report}},
  year        = {2013},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D61.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@InProceedings{Paletta2005a_icml_q-learning-sequential-attention,
  author    = {Lucas Paletta and Gerald Fritz and Christin Seifert},
  booktitle = {Proc. 22nd International Conference on Machine Learning, {ICML} 2005},
  title     = {Q-Learning of Sequential Attention for Visual Object Recognition from Informative Local Descriptors},
  year      = {2005},
  address   = {Bonn, Germany},
  month     = {8},
  pages     = {649--656},
  abstract  = {This work provides a framework for learning sequential attention in real-world visual object recognition, using an architecture of three processing stages. The rst stage rejects irrelevant local descriptors based on an information theoretic saliency measure, providing candidates for foci of interest (FOI). The second stage investigates the information in the FOI using a codebook matcher and providing weak object hypotheses. The third stage integrates local information via shifts of attention, resulting in chains of descriptor-action pairs that characterize object discrimination. A Q-learner adapts then from explorative search and evaluative feedback from entropy decreases on the attention sequences, eventually prioritizing shifts that lead to a geometry of descriptor-action scanpaths that is highly discriminative with respect to object recognition. The methodology is successfully evaluated on indoors (COIL-20 database) and outdoors (TSG-20 database) imagery, demonstrating signi cant impact by learning, outperforming standard local descriptor based methods both in recognition accuracy and processing time.},
  file      = {:own/Paletta2005a.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005b_icdl_reinforcement-learning-of-attention-patterns-object-recognition,
  author    = {Lucas Paletta and Gerald Fritz and Christin Seifert},
  booktitle = {Proc. 4th {IEEE} International Conference on Development and Learning (ICDL)},
  title     = {Reinforcement Learning of Informative Attention Patterns for Object Recognition},
  year      = {2005},
  address   = {Osaka, Japan},
  month     = {7},
  pages     = {188--193},
  abstract  = {Attention is a highly important phenomenon emerging in infant development [1]. In human perception, sequential visual sampling about the environment is mandatory for object recognition purposes. Sequential attention is viewed in the framework of a saccadic decision process that aims at minimizing the uncertainty about the semantic interpretation for object or scene recognition. Methodologically, this work provides a framework for learning sequential attention in real-world visual object recognition, using an architecture of three processing stages. The first stage rejects irrelevant local descriptors providing candidates for foci of interest (FOI). The second stage investigates the information in the FOI using a codebook matcher. The third stage integrates local information via shifts of attention to characterize object discrimination. A Q-learner adapts then from explorative search on the FOI sequences. The methodology is successfully evaluated on representative indoors and outdoors imagery, demonstrating the significant impact of the learning procedures on recognition accuracy and processing time.},
  file      = {:own/Paletta2005b.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005c_scia_object-detection-reinforcement-learning,
  author    = {Lucas Paletta and Gerald Fritz and Christin Seifert},
  booktitle = {Proc. 19th Scandinavian Conference on Image Analysis, (SCIA)},
  title     = {Perception-Action Based Object Detection From Local Descriptor Combination And Reinforcement Learning},
  year      = {2005},
  address   = {Joensuu, Finland},
  month     = {6},
  number    = {3540},
  pages     = {639--648},
  publisher = {Springer-Verlag},
  series    = {Lecture Notes in Computer Science, LNCS},
  abstract  = {This work proposes to learn visual encodings of attention patterns that enables sequential attention for object detection in real world environments. The system embeds a saccadic decision procedure in a cascaded process where visual evidence is probed at informative image locations. It is based on the extraction of information theoretic saliency by determining informative local image descriptors that provide selected foci of interest. The local information in terms of code book vector responses and the geometric information in the shift of attention contribute to recognition states of a Markov decision process. A Q-learner performs then performs search on useful actions towards salient locations, developing a strategy of action sequences directed in state space towards the optimization of information maximization. The method is evaluated in outdoor object recognition and demonstrates efficient performance.},
  file      = {:own/Paletta2005c.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005d_wapcv-ws_cascaded-sequential-attention-q-learning-grouping,
  author    = {Lucas Paletta and Gerald Fritz and Christin Seifert},
  booktitle = {Proc. {CVPR} 3rd International Workshop on Attention and Performance in Computational Vision, {WAPCV}},
  title     = {Cascaded Sequential Attention for Object Recognition with Informative Local Descriptors and Q-learning of Grouping Strategies},
  year      = {2005},
  address   = {San Diego, CA},
  month     = {6},
  abstract  = {The contribution of this work is to provide a three-stage architecture for sequential attention to provide a system being capable of sensorimotor object detection in real world environments. The first processing stage provides selected foci of interest in the image based on the extraction of information theoretic saliency of local image descriptors (i-SIFT). The second stage investigates the information in the local attention window using a codebook matcher, providing local weak hypotheses about the identity of the object under investigation. The third stage then proposes a shift of attention to a next attention window. The working hypothesis is to expect a better discrimination from the integration of both the individual local {FOA} patterns and the geometric relation between them, providing a model of more global information representation, and feeding into a recognition state in the Markov Decision Process ({MDP}). A reinforcement learner (Q-learner) performs then explorative search on useful actions, i.e., shifts of attention, towards locations of salient information, developing a strategy of useful action sequences being directed in state space towards the optimization of discrimination by information maximization. The method is evaluated in experiments using the COIL-20 database (indoor imagery) and the TSG-20 database (outdoor imagery) to demonstrate efficient performance in object detection tasks, proving the method being more accurate and computationally much less expensive than standard SIFT based recognition},
  file      = {:own/Paletta2005d.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005i_hacippr_sequential-attention-for-object-discrimination,
  author    = {Lucas Paletta and Gerald Fritz and Christin Seifert},
  booktitle = {Proc. Joint Hungarian-Austrian Conference on Image Processing and Pattern Recognition, {HACIPPR}},
  title     = {Sequential Attention for Object Discrimination Using Reinforcement Learning from Informative Descriptors},
  year      = {2005},
  address   = {Veszprem, Hungary},
  month     = {5},
  pages     = {79--86},
  abstract  = {This work proposes to learn visual encodings of attention patterns that enables sequential attention for object detection in real world environments. The system embeds a saccadic decision procedure in a cascaded process where visual evidence is probed at informative image locations. It is based on the extraction of information theoretic saliency by determining informative local image descriptors that provide selected foci of interest. The local information in terms of code book vector responses and the geometric information in the shift of attention contribute to recognition states of a Markov decision process. A Q-learner performs then performs search on useful actions towards salient locations, developing a strategy of action sequences directed in state space towards the optimization of information maximization. The method is evaluated in outdoor object recognition and demonstrates efficient performance.},
  file      = {:own/Paletta2005i.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2006_itsc_mobile-vision-tourist-application,
  author    = {Lucas Paletta and Gerald Fritz and Christin Seifert and Patrick Luley and Alexander Almer},
  booktitle = {Proc {IEEE} Intelligent Transportation System Conference ({ITSC}2006)},
  title     = {A Mobile Vision System for Multimedia Tourist Applications in Urban Environment},
  year      = {2006},
  address   = {Toronto, Canada},
  month     = {9},
  abstract  = {We present a computer vision system for the detection and identification of urban objects from mobile phone imagery, e.g., for the application of tourist information services. Recognition is based on MAP decision making over weak object hypotheses from local descriptor responses in the mobile imagery. We present an improvement over the standard SIFT key detector [1] by selecting only informative (i-SIFT) keys for descriptor matching. Selection is applied first to reduce the complexity of the object model and second to accelerate detection by selective filtering. We present results on the MPG-20 mobile phone imagery with severe illumination, scale and viewpoint changes in the images, performing with 98\% accuracy in identification, efficient (100\%) background rejection, effficient (0\%) false alarm rate, and reliable quality of service under extreme illumination conditions, significantly improving standard SIFT based recognition in every sense, providing (important for mobile vision ) runtimes which are 8 (24) times faster for the MPG-20 (ZuBuD) database.},
  file      = {:own/Paletta2006.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005f_tcmc-ws_mobile-object-recognition-tourist,
  author     = {Lucas Paletta and Gerald Fritz and Christin Seifert and Patrick Luley and Alexander Almer},
  booktitle  = {Proc. Workshop on Wearable and Pervasive Computing, Telecommunications and Mobile Computing Graz Series, {TCMC}},
  title      = {Visual Object Recognition in Mobile Imagery for Situated Tourist Information Systems},
  year       = {2005},
  address    = {Graz, Austria},
  month      = {3},
  abstract   = {We describe a system with a multi-sensor object awareness and positioning solution for augmented tourist information systems in urban areas. The system offers technology of outdoors vision based object recognition that will extend state-of-the-art location and context aware services towards object based awareness in urban environments. In the proposed application scenario, tourist pedestrians are equipped with a GPRS or UMTS capable camera-phone. They are interested whether their field of view contains tourist sights that would point to more detailed information. Multimedia type data about related history might be explored by a mobile user who is intending to learn within the urban environment. Ambient learning is in this way achieved by pointing the device towards the urban sight, capturing an image, and consequently getting information about the object on site and within the focus of attention, i.e., the user's current field of view. The described mobile system offers multiple opportunities for application in both mobile business and commerce, and is currently developed towards an industrial prototype.},
  bdsk-url-1 = {http://tcmc.tugraz.at/tcmc2005/PDF/tcmc2005-paletta-final.pdf},
  file       = {:own/Paletta2005f.pdf:PDF},
  owner      = {sech},
  timestamp  = {2007.11.04},
  url        = {http://tcmc.tugraz.at/tcmc2005/PDF/tcmc2005-paletta-final.pdf},
}

@InProceedings{Paletta2005g_gnss_mobile-application-system-object-and-position-awareness,
  author    = {Lucas Paletta and Patrick Luley and Alexander Almer and Gerald Fritz and Christin Seifert and Harald Stelzl and Mathias Schardt},
  booktitle = {Proc. European Conference on {N}avigation, {GNSS}},
  title     = {Mobile Application Systems using Visual Object and Position Awareness},
  year      = {2005},
  address   = {Munich, Germany},
  month     = {7},
  abstract  = {We describe a system which includes a multi-sensor object awareness and positioning solution to enable stable location awareness for a mobile service in urban areas. The system offers technology of outdoor vision based object recognition that will extend state-of-the-art location and context aware services towards object based awareness in urban environments. In the proposed application scenario, tourist pedestrians are equipped with a GPRS or UMTS capable camera-phone. They are interested whether their field of view contains tourist sights that would point to more detailed information. Multimedia type data about related history might be explored by a mobile user who is intending to learn within the urban environment. Situated learning is in this way achieved by pointing the device towards the urban sight, capturing an image, and consequently getting information about the object on site and within the focus of attention, i.e., the user's current field of view. The described mobile system offers multiple opportunities for application in both mobile business and commerce, and is currently developed towards an industrial prototype.},
  file      = {:own/Paletta2005g.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005h_asvw-ws_sequential-attention-and-saccadic-grouping-object-discrimination,
  author    = {Lucas Paletta and Christin Seifert and Gerald Fritz},
  booktitle = {Proc. 1st Austrian Cognitive Vision Workshop, {ACVW}},
  title     = {Sequential Attention and Saccadic Grouping for Object Discrimination Using Reinforcement Learning},
  year      = {2005},
  address   = {Zell an der Pram, Austria},
  month     = {1},
  pages     = {99--106},
  abstract  = {An important issue in sequential object recognition is to de ne a strategy for saccadic access of visual information, and the representation of the features under observation. The original contribution of this work is to embed the saccadic decision procedure in a cascaded recognition process where visual evidence is probed exclusively at salient image locations. In a rst processing stage, salient image locations are determined from the local entropy in object discrimination. Local information in terms of code book vector responses contribute to the recognition state in the {MDP}. A reinforcement learner performs then trial and error search on useful actions towards salient locations within a neighborhood, receiving reward from entropy decreases. The method is evaluated in experiments on object recognition using the COIL-20 database, proving the method being computationally feasible and providing high recognition rates.},
  file      = {:own/Paletta2005h.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Paletta2005j_ecvp_contextual-working-memory-trans-saccadic-object-recognition,
  author     = {Lucas Paletta and Christin Seifert and Gerald Fritz},
  booktitle  = {Proc. European Conference on Visual Perception, {ECVP}},
  title      = {Contextual Working Memory for Trans-Saccadic Object Recognition Using Reinforcement Learning and Informative Local Descriptors},
  year       = {2005},
  address    = {Coruna, Spain},
  month      = {8},
  pages      = {69},
  bdsk-url-1 = {http://www.perceptionweb.com/ecvp05/0402.html},
  file       = {:own/Paletta2004a.pdf:PDF},
  owner      = {sech},
  timestamp  = {2007.11.04},
  url        = {http://www.perceptionweb.com/ecvp05/0402.html},
}

@InProceedings{Paletta2004a_ecvp_saccadic-object-recognition-mdp,
  author    = {Lucas Paletta and Christin Seifert and Gerald Fritz},
  booktitle = {Proc. European Conference on Visual Perception, {ECVP}},
  title     = {Saccadic Object Recognition using a Markov Decision Process in a Cascaded Framework},
  year      = {2004},
  address   = {Budapest, Hungary},
  month     = {8},
  pages     = {126},
  file      = {:own/Paletta2004a.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Pianos2016_library20_eexcess-project,
  author     = {Tamara Pianos and Christin Seifert},
  booktitle  = {Library 2.016 -- Libraries of the Future},
  title      = {Bringing Library Content to the Users with EEXCESS-Extensions and Plugins. Open Source Solutions to distribute Cultural and Scientific Content},
  year       = {2016},
  month      = {10},
  abstract   = {The EC-funded project EEXCESS developed a number of tools that help to inject relevant content in a privacy preserving manner into platforms that readers, students and researchers use in their daily work. One prototype is a Google Chrome Extension that can be used to get recommendations for related content from quality sources. A visualization dashboard with many different options can be used to filter the results. Users who are searching a specific topic e.g. in Wikipedia can find more related quality content on their topic through the Chrome Extension. Users who write a text in Google Docs can use the plugin to get references etc.

All EEXCESS developments are open source and can be used and adapted freely.
Libraries or cultural institutions like museums etc. who own repositories can submit their content for inclusion into EEXCESS. Among the content providers so far are Europeana, Mendeley, The Digital Public Library of America , The National Archives UK, Swissbib, Deutsche Digitale Bibliothek, Rijksmuseum {\^a} The Museum of the Netherlands, and Core.ac.uk, so that more than 150 Mio items are potentially recommended through EEXCESS. New content can be easily submitted through an Application Program Interface (API) supporting search functionalities.

A number of prototypes were developed in the project that are now available for public use. The benefit of the prototypes so far still depends on the focus of the search. As more content partners are included the recommendations cover more and more subject areas.

Privacy preservation is one of the key objectives of the project.},
  bdsk-url-1 = {https://sas.elluminate.com/site/external/recording/playback/link/table/dropin?sid=2008350&suid=D.0577D13554BD16389A48519B0399D8%20https://sas.elluminate.com/site/external/recording/playback/link/table/dropin?sid=2008350&suid=D.0577D13554BD16389A48519B0399D8},
  file       = {online submission:own/Pianos2016_library20_Bringing-Library-Content-to-the-Users.pdf:PDF},
  url        = {https://sas.elluminate.com/site/external/recording/playback/link/table/dropin?sid=2008350&suid=D.0577D13554BD16389A48519B0399D8 https://sas.elluminate.com/site/external/recording/playback/link/table/dropin?sid=2008350&suid=D.0577D13554BD16389A48519B0399D8},
}

@InProceedings{Sabol2012_sigrad_visual-ontology-alignment-system,
  author    = {Vedran Sabol and Weng Onn Kow and Manuela Rauch and Eva Ulbrich and Christin Seifert and Michael Granitzer and Dickson Lukose},
  booktitle = {Proceedings of SIGRAD},
  title     = {Visual Ontology Alignment System - an Evaluation},
  year      = {2012},
  month     = {11},
  abstract  = {Ontology alignment is the process of mapping related concepts from different ontologies. A lot of research effort has been invested in development of algorithmic methods supporting automatic discovery of mappings between ontological concepts. However, automatic alignment remains potentially prone to errors especially with large real-world ontologies, demanding intervention of domain experts. We therefore created a semi-automatic tool including algorithmic alignment methods and an interactive visual interface. Visualisation components included in the interface support experts in navigating the concept space and reviewing the automatically generated mapping suggestions. An experiment with 15 test users was performed to evaluate whether, and in which cases the use of visualisation is beneficial compared to a user interface employing standard GUI widgets. The results indicate that users typically executed tasks slightly faster with an interface using standard widgets, but an interface which includes a visualisation component providing overview, filter and narrowing-down functionality achieved higher rates of successful task completion.},
  file      = {:own/Sabol2012_sigrad_visual-ontology-alignment-evaluation.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.11.02},
}

@InProceedings{Sabol2010_eurovis_information-landscapes-node-link-diagrams,
  author    = {Vedran Sabol and Christin Seifert and Wolfgang Kienreich},
  booktitle = {Proceedings European Conference on Visualization (EuroVis)},
  title     = {Integrating Node-Link-Diagrams and Information Landscapes: A Path-Finding Approach},
  year      = {2010},
  month     = jun,
  note      = {Poster and Demo at Eurovis 2010},
  abstract  = {Knowledge repositories usually contain semantic structures as well as massive amounts of content. Information Landscapes have commonly been used to visualize large content repositories, and Node-Link Diagrams have commonly been used to visualize semantic structures. We present preliminary research on a path finding approach to the integration of Information Landscapes and Node-Link Diagrams. Our approach is based on a link-specific height map which reflects the semantic properties of the content in relation to the link. The paths generated by our approach tend to reduce the amount of contradictory visual evidence and to respect terrain features.},
  file      = {:own/Sabol2010_eurovis-poster_path-finding.pdf:PDF},
  owner     = {sech},
  timestamp = {2010.05.19},
}

@InProceedings{Schloetterer2016_tpdl_supporting-web-surfers-digital-libraries,
  author    = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Michael Granitzer},
  booktitle = {Proc. International Conference on Theory and Practice of Digital Libraries (TPDL)},
  title     = {{Supporting Web Surfers in Finding Related Material in Digital Library Repositories}},
  year      = {2016},
  file      = {:own/Schloetterer2016_tpdl_query-generation.pdf:PDF},
  owner     = {sech},
  timestamp = {2016.07.24},
}

@InProceedings{Schloetterer2014_patch-ws_web-based-just-in-time-retrieval,
  author    = {Schl\"{o}tterer, J\"{o}rg and Seifert, Christin and Granitzer, Michael},
  booktitle = {PATCH '14: Proceedings of the 7th International {ACM} Workshop on Personalized Access to Cultural Heritage},
  title     = {Web-based Just-In-Time Retrieval for Cultural Content},
  year      = {2014},
  month     = {2},
  file      = {:own/Schloetterer2014_patch_jitr-for-cultural-content.pdf:PDF},
  owner     = {sech},
  timestamp = {2014.02.12},
}

@InProceedings{Schloetterer2014a_iknow_browser-based-suggestions-of-long-tail-resources,
  author    = {Schl\"{o}tterer, J\"{o}rg and Seifert, Christin and Kern, Roman and Granitzer, Michael},
  booktitle = {Demos at International Conference on Knowledge Technologies and Data-driven Business},
  title     = {From Tail to Head: Browser Based Suggestion of Long-tail Resources},
  year      = {2014},
  month     = {9},
  note      = {Demo at I-Know},
  series    = {I-Know},
  file      = {:own/Schloetterer2014a_ikknowdemo_browser-based-suggestion-of-longtail-resources.pdf:PDF},
  owner     = {sech},
  timestamp = {2014.08.26},
}

@InProceedings{Schloetterer2015a_ecir_mobile-just-in-time-retrieval,
  author        = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Wolfgang Lutz and Michael Granitzer},
  booktitle     = {Proc. European Conference on IR Research (ECIR 2015)},
  title         = {{From Context-Aware to Context-Based: Mobile Just-In-Time Retrieval of Cultural Heritage Objects}},
  year          = {2015},
  address       = {Vienna, Austria},
  editor        = {Allan Hanbury and Gabriella Kazai and Andreas Rauber and Norbert Fuhr:},
  month         = {3},
  number        = {9022},
  pages         = {805--808},
  publisher     = {Springer},
  series        = {LNCS},
  doi           = {10.1007/978-3-319-16354-3_90},
  file          = {:own/Schloetterer2015a_ecirdemo_eexcess-android-app.pdf:PDF},
}

@InProceedings{Schloetterer2015_gamifir-ws_gwap-access-to-culture,
  author        = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Lisa Wagner and Michael Granitzer},
  booktitle     = {Proceedings of the Second International Workshop on Gamification for Information Retrieval},
  title         = {{A Game with a Purpose to Access Europe's Cultural Treasure}},
  year          = {2015},
  month         = {3},
  bdsk-url-1    = {http://ceur-ws.org/Vol-1345/gamifir15_2.pdf},
  date-added    = {2015-03-30 06:58:40 +0000},
  date-modified = {2015-03-30 08:52:35 +0000},
  file          = {:own/Schloetterer2015_gamifir_Cultural-Game-with-a-Purpose_presentation.pdf:PDF;:own/Schloetterer2015_gamifir_Cultural-Game-with-a-Purpose.pdf:PDF},
  url           = {http://ceur-ws.org/Vol-1345/gamifir15_2.pdf},
}

@TechReport{EEXCESS-D54_final-prototype-user-profile-context-detection,
  author      = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Nils Witt and Johannes Jurgovsky and Stefan Zwicklbauer},
  institution = {University of Passau},
  title       = {{D5.4 -- Final Prototype on User Profile and Context Detection, Usage Analysis Methods and Services}},
  year        = {2016},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D54.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.07.24},
}

@InProceedings{Schlegel2013_eswc_triplifying-research-data-provenance,
  author    = {Kai Schlegel and Sebastian Bayerl and Stefan Zwicklbauer and Florian Stegmaier and Christin Seifert and Michael Granitzer and Harald Kosch},
  booktitle = {Proceedings of the 10th European Semantic Web Conference},
  title     = {Trusted Facts: Triplifying Primary Research Data Enriched with Provenance Information},
  year      = {2013},
  address   = {Montpellier, France},
  month     = {5},
  note      = {poster},
  file      = {:own/Schlegel2013_eswc_CODE-project-intro.pdf:PDF},
  owner     = {sech},
  timestamp = {2013.06.12},
}

@InProceedings{Schlegel2014_eswc_rdf-viewer-and-browser-web,
  author    = {Kai Schlegel and Thomas Wei{\ss}gerber and Florian Stegmaier and Christin Seifert and Michael Granitzer and Harald Kosch},
  booktitle = {Post-Conference Proceedings of 11th European Semantic Web Conference},
  title     = {Balloon Synopsis: A Modern Node-Centric {RDF} Viewer and Browser for the Web},
  year      = {2014},
  month     = {5},
  file      = {:own/Schlegel2014_eswc-poster_balloon-synopsis-rdf-vis.pdf:PDF},
  owner     = {sech},
  timestamp = {2014.06.03},
}

@PhdThesis{Seifert2012_phd-thesis,
  author    = {Christin Seifert},
  school    = {Graz University of Technology},
  title     = {Visually Supported Supervised Machine Learning},
  year      = {2012},
  month     = {5},
  file      = {:own/Seifert2012_phdthesis.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.08.08},
}

@InProceedings{Seifert2004_gi_immune-systems-simulator,
  author    = {Christin Seifert},
  booktitle = {Tagungsband: Informatiktage 2003. Fachwissenschaftlicher Informatik-Kongress},
  title     = {AIMS2 - Ein Immunsystem-Simulator},
  year      = {2004},
  address   = {Bad Schussenried},
  pages     = {80--83},
  publisher = {Konradin Verlagsgruppe},
  file      = {:own/Seifert2004_giinformatiktage_immunsystemsimulator.pdf:PDF;Presentation:own/Seifert2004_giinformatiktage_immunsystemsimulator_presentation.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.12.17},
}

@MastersThesis{Seifert2004a_msc_thesis_simulator-immune-system,
  author     = {Christin Seifert},
  school     = {Chemnitz University of Technology},
  title      = {Ein Simulator f{\"u}r das Immunsystem},
  year       = {2004},
  month      = {2},
  bdsk-url-1 = {http://archiv.tu-chemnitz.de/pub/2004/0012},
  file       = {:own/Seifert2004a_Diplomarbeit.pdf:PDF;presentation:own/Seifert2004a_Diplomarbeit_presentation.pdf:PDF},
  owner      = {sech},
  timestamp  = {2012.12.17},
  url        = {http://archiv.tu-chemnitz.de/pub/2004/0012},
}

@InCollection{Seifert2017a_sbd_survey-visualizations-dnn,
  author     = {Seifert, Christin and Aamir, Aisha and Balagopalan, Aparna and Jain, Dhruv and Sharma, Abhinav and Grottel, Sebastian and Gumhold, Stefan},
  booktitle  = {Transparent Data Mining for Big and Small Data},
  publisher  = {Springer},
  title      = {Visualizations of Deep Neural Networks in Computer Vision: A Survey},
  year       = {2017},
  address    = {Cham},
  editor     = {Cerquitelli, Tania and Quercia, Daniele and Pasquale, Frank},
  isbn       = {978-3-319-54024-5},
  pages      = {123--144},
  doi        = {10.1007/978-3-319-54024-5_6},
  file       = {:own/Seifert2017a_glassboxdm_vis-of-dnn-survey_preprint.pdf:PDF},
}

@Article{Seifert2017_joch_access-to-digital-cultural-heritage,
  author     = {Seifert, Christin and Bailer, Werner and Orgel, Thomas and Gantner, Louis and Kern, Roman and Ziak, Hermann and Petit, Albin and Schl\"{o}tterer, J\"{o}rg and Zwicklbauer, Stefan and Granitzer, Michael},
  journal    = {J. Comput. Cult. Herit.},
  title      = {Ubiquitous Access to Digital Cultural Heritage},
  year       = {2017},
  issn       = {1556-4673},
  month      = {4},
  number     = {1},
  pages      = {4:1--4:27},
  volume     = {10},
  acmid      = {3012284},
  address    = {New York, NY, USA},
  articleno  = {4},
  doi        = {10.1145/3012284},
  file       = {:own/Seifert2017_jocch_ubiquitous-access-to-digital-cultural-heritage.pdf:PDF},
  issue_date = {April 2017},
  keywords   = {Search aggregation, metadata harmonization, user context detection},
  numpages   = {27},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/3012284},
}

@InProceedings{Seifert2006_ecvp_local-descriptor-groupings,
  author       = {Christin Seifert and Gerald Fritz and Lucas Paletta},
  booktitle    = {European Conference on Visual Perception ({ECVP}2006)},
  title        = {Local Descriptor Groupings in Reinforcement Learning of Sensory-Motor Attention},
  year         = {2006},
  address      = {St. Petersburg, Russia},
  month        = {8},
  organization = {Proc. of 29th European Conference on Visual Perception (ECVP 2006)},
  pages        = {48},
  publisher    = {Pion Ltd, London, UK},
  series       = {abstracts},
  volume       = {35},
  abstract     = {Previous research on behavioural modelling of saccadic image interpretation (Henderson, 1982 Psychological Science 8 51 - 55) has emphasised the sampling of informative parts under visual attention to guide visual perception. We propose a system of sequential attention for object recognition that (i) groups n-tuples of local gradient based image descriptors (Lowe, 2004 International Journal of Computer Vision 60 91 - 110) being scale, rotation, and to high degree illumination tolerant, defining a vocabulary of prototypical code descriptors, (ii) selects only informative groupings for further processing, (iii) learns a predictive mapping from a current perceptual state in a Markov decision process to a next saccadic action, and (iv) present a model of object recognition being capable of integrating sequential information by minimization of entropy in the Bayesian modelling of object hypotheses. The innovative abstraction level of informative groupings provides perceptual meta-states in sensory-motor attention, enabling the learning of a purposeful grammar integrating atomic feature-saccade mappings into a meaningful recognition behaviour. We demonstrate highly accurate recognition of outdoor facades in a mobile vision application, using the sensory-motor context of trans-saccadic object recognition.},
  file         = {:own/Seifert2006.pdf:PDF},
  owner        = {sech},
  timestamp    = {2007.11.04},
}

@InProceedings{Seifert2005_acvw-ws_informative-sift-object-recognition,
  author    = {Christin Seifert and Gerald Fritz and Lucas Paletta and Horst Bischof},
  booktitle = {Proc. 1st Austrian Cognitive Vision Workshop, {ACVW}},
  title     = {Learning Informative SIFT Descriptors for Attentive Object Recognition},
  year      = {2005},
  address   = {Zell an der Pram, Austria},
  month     = {1},
  pages     = {67--74},
  abstract  = {With the emerging sensor technologies in mobile devices, such as camera phones, visual interpretation methodologies are challenged to provide solutions within the everydays outdoor urban environment. For this purpose, we propose to apply the 'Informative Descriptor Approach' on the SIFT descriptor [4], in order to define the informative SIFT (i-SIFT) descriptor. By attentive matching of i-SIFT keypoints, we provide an innovative method on object detection that significantly improves SIFT based keypoint matching. i-SIFT tackles the SIFT bottlenecks, e.g., extensive nearest neighbor indexing, by (i) significantly reducing the descriptor dimensionality, (ii) decreasing the size of object representation by one order of magnitude, and (iii) performing matching exclusively on attended descriptors, as required by resource sensitive devices. The key advantages of informative SIFT (i-SIFT) are demonstrated in a typical outdoor mobile vision experiment on the TSG-20 reference database, detecting buildings with high accuracy.},
  file      = {:own/Seifert2005.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Seifert2010b_icdm-ws_user-based-active-learning,
  author     = {Christin Seifert and Michael Granitzer},
  booktitle  = {Proceedings of 10th International Conference on Data Mining Workshops (ICDM2010)},
  title      = {User-based active learning},
  year       = {2010},
  address    = {Sydney, Australia},
  editor     = {Wei Fan and Wynne Hsu and Geoffrey I. Webb and Bing Liu and Chengqi Zhang and Dimitrios Gunopulos and Xindong Wu},
  month      = dec,
  pages      = {418--425},
  abstract   = {Active learning has been proven a reliable strategy to reduce manual efforts in training data labeling. Such strategies incorporate the user as oracle: the classifier selects the most appropriate example and the user provides the label. While this approach is tailored towards the classifier, more intelligent input from the user may be beneficial. For instance, given only one example at a time users are hardly able to determine whether this example is an outlier or not. In this paper we propose user-based visually-supported active learning strategies that allow the user to do both, selecting and labeling examples given a trained classifier. While labeling is straightforward, selection takes place using a interactive visualization of the classifier's a-posteriori output probabilities. By simulating different user selection strategies we show, that user-based active learning outperforms uncertainty based sampling methods and yields a more robust approach on different data sets. The obtained results point towards the potential of combining active learning strategies with results from the field of information visualization.},
  doi        = {10.1109/ICDMW.2010.181},
  file       = {:own/Seifert2010b_icdmw-vakd_user-based-active-learning.pdf:PDF},
  owner      = {sech},
  timestamp  = {2011.01.03},
}

@Article{Seifert2015a_iwp_eexcess-project,
  author     = {Christin Seifert and Michael Granitzer},
  journal    = {Information - Wissenschaft \& Praxis},
  title      = {EEXCESS: Personalised access to Long Tail content -- New strategies for disseminating scientific and cultural content},
  year       = {2015},
  issn       = {1619-4292 (Online)},
  month      = {4},
  note       = {german},
  number     = {2--3},
  pages      = {103--110},
  volume     = {66},
  doi        = {10.1515/iwp-2015-0022},
  file       = {:own/Seifert2015a_iwpj_eexcess-overview_preprint.pdf:PDF;:own/Seifert2015a_iwpj_eexcess-overview_publisher.pdf:PDF},
  owner      = {sech},
  timestamp  = {2015.05.04},
  url        = {http://www.degruyter.com/view/j/iwp.2015.66.issue-2-3/iwp-2015-0022/iwp-2015-0022.xml},
}

@InProceedings{Seifert2013a_southchi_crowdsourcing-fact-extraction-from-scientific-literature,
  author    = {Christin Seifert and Michael Granitzer and Patrick H\"{o}fler and Belgin Mutlu and Vedran Sabol and Kai Schlegel and Sebastian Bayerl and Florian Stegmaier and Stefan Zwicklbauer and Roman Kern},
  booktitle = {Proc. Conference on Human Computer Interaction and Knowledge Discovery (SouthCHI)},
  title     = {Crowdsourcing Fact Extraction from Scientific Literature},
  year      = {2013},
  address   = {Maribor, Slovenia},
  month     = {7},
  pages     = {160--172},
  publisher = {Springer},
  series    = {LNCS},
  volume    = {7947},
  file      = {:own/Seifert2013a_hcikdd_fact-extraction-from-scientific-papers-visual.pdf:PDF},
  owner     = {sech},
  timestamp = {2013.05.13},
}

@InProceedings{Seifert2014a_iv_facetscape,
  author     = {Christin Seifert and Johannes Jurgovsky and Michael Granitzer},
  booktitle  = {Proc. International Conference on Information Visualization (IV)},
  title      = {FacetScape: A Visualization for Exploring the Search Space},
  year       = {2014},
  month      = jul,
  note       = {\textbf{Best Paper Award}},
  pages      = {94--101},
  publisher  = {IEEE Computer Society},
  abstract   = {Despite advancing search technologies, information overload has not yet been solved. Getting an overview of information or explorative access to information becomes increasingly difficult with the exponentially increasing amount of information. Search result visualizations, especially for faceted browsing, aim at supporting users to find their way through large document collections. We propose FacetScape, a novel visualization for navigation and refinement of search results allowing users to visually construct complex boolean search queries for narrowing down the search space. This visualization combines Voronoi subdivision and a tag cloud representation of the search facets. Further it includes a preview of action (query preview) and interactions to allow users to focus on important aspects of the data for the task at hand. In a comparative user study with 15 users we compared the visualization to a standard faceted browsing interface for different types of search tasks. The study revealed that participants used the unfamiliar interface as efficiently and effectively as the familiar tree-like display. Results indicate that the FacetScape is a promising way of supporting users in exploring the faceted search space.},
  doi        = {10.1109/IV.2014.49},
  file       = {:own/Seifert204a_iv_facetscape.pdf:PDF;Presentation:own/Seifert2014a_iv_facetscape_presentation.pdf:PDF},
  owner      = {sech},
  timestamp  = {2014.05.15},
}

@TechReport{CODE-D22_coreference-resolution-in-academic-research-papers,
  author      = {Christin Seifert and Roman Kern and Michael Granitzer},
  institution = {Technical University of Graz},
  title       = {{D2.2 -- Performance report of coreference resolution in academic research papers}},
  year        = {2011},
  type        = {TEAM Project Deliverable},
  file        = {:own/CODE-D22.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@InProceedings{Seifert2011_iv-poster_voronoi-word-clouds,
  author    = {Christin Seifert and Wolfgang Kienreich and Michael Granitzer},
  booktitle = {Proceedings 15th International Conference Information Visualisation (IV)},
  title     = {Visualizing Text Classification Models with Voronoi Word Clouds},
  year      = {2011},
  series    = {IV},
  file      = {:own/Seifert2011_iv-poster_voronoi-word-clouds_abstract.pdf:PDF},
  owner     = {sech},
  timestamp = {2011.09.27},
}

@InProceedings{Seifert2008_iv_tag-clouds,
  author     = {Christin Seifert and Barbara Kump and Wolfgang Kienreich and Gisela Granitzer and Michael Granitzer},
  booktitle  = {Proceedings of the 12th International Conference on Information Visualisation (IV)},
  title      = {On the beauty and usability of tag clouds},
  year       = {2008},
  address    = {Los Alamitos, CA, USA},
  month      = {7},
  pages      = {17--25},
  publisher  = {IEEE Computer Society},
  abstract   = {Tag clouds are text-based visual representations of a set of tags usually depicting tag importance by font size. Recent trends in social and collaborative software have greatly increased the popularity of this type of visualization. This paper proposes a family of novel algorithms for tag cloud layout and presents evaluation results obtained from an extensive user study and a technical evaluation. The algorithms address issues found in many common approaches, for example large whitespaces, overlapping tags and restriction to specific boundaries. The layouts computed by these algorithms are compact and clear, have small whitespaces and may feature arbitrary convex polygons as boundaries. The results of the user study and the technical evaluation enable designers to devise a combination of algorithm and parameters which produces satisfying tag cloud layouts for many application scenarios.},
  bdsk-url-1 = {http://doi.ieeecomputersociety.org/10.1109/IV.2008.89},
  doi        = {http://doi.ieeecomputersociety.org/10.1109/IV.2008.89},
  file       = {:own/Seifert2008_iv_tagclouds.pdf:PDF},
  owner      = {sech},
  timestamp  = {2008.05.06},
}

@InProceedings{Seifert2009_eurovis_visualization-classifiers,
  author    = {Christin Seifert and Elisabeth Lex},
  booktitle = {Proceedings European Conference on Visualization (EuroVis)},
  title     = {A Visualization to Investigate and Give Feedback to Classifiers},
  year      = {2009},
  month     = {6},
  note      = {poster},
  file      = {:own/Seifert2009-eurovis-poster-abstract.pdf:PDF},
  owner     = {sech},
  timestamp = {2009.07.09},
}

@InProceedings{Seifert2009a_iv_visualzation-dclassification,
  author    = {Christin Seifert and Elisabeth Lex},
  booktitle = {Proc. of the International Conference on Information Visualisation (IV)},
  title     = {A Novel Visualization Approach for Data-Mining-Related Classification},
  year      = {2009},
  month     = jul,
  pages     = {490--495},
  publisher = {Wiley},
  abstract  = {Classification and categorization are common tasks in data mining and knowledge discovery. Visualizations of classification models can create understanding and trust in data mining models. However, existing visualizations are often complex or restricted to specific classifiers and attributes. In this work, we propose an intuitive visualization system to observe and understand classification processes and results. Our system can handle multiple classes, nominal and numeric attributes, and supports all classifiers whose predictions can be interpreted as probabilities. We state that the possibility to observe the training process of a classifier boosts the understanding of classification results also for non-expert users. In combination with an intuitive visualization, we provide a system to generate in-depth understanding of classification processes and results. Our simulations revealed that the system could support the user to better understand a classifier's decision, and to gain insights into classification processes.},
  file      = {:own/Seifert2009a_iv_classvis.pdf:PDF},
  owner     = {sech},
  timestamp = {2009.07.27},
}

@InProceedings{Seifert2017b_chiir_focus-paragraph-detection-eye-tracking,
  author     = {Seifert, Christin and Mitschick, Annett and Schl\"{o}tterer, J\"{o}rg and Dachselt, Raimund},
  booktitle  = {Proceedings Conference Human Information Interaction and Retrieval},
  title      = {Focus Paragraph Detection for Online Zero-Effort Queries: Lessons Learned from Eye-Tracking Data},
  year       = {2017},
  address    = {New York, NY, USA},
  pages      = {301--304},
  publisher  = {ACM},
  series     = {CHIIR},
  acmid      = {3022138},
  doi        = {10.1145/3020165.3022138},
  file       = {:own/Seifert2017b_chiir_paragraph-detection-eye-tracking.pdf:PDF},
  isbn       = {978-1-4503-4677-1},
  keywords   = {eye tracking, focus paragraph detection, zero-effort queries},
  location   = {Oslo, Norway},
  numpages   = {4},
  url        = {http://doi.acm.org/10.1145/3020165.3022138},
}

@InProceedings{Seifert2010a_ndt_classifier-hypothesis-generation-visual-analysis,
  author    = {Christin Seifert and Vedran Sabol and Michael Granitzer},
  booktitle = {Proc. of Networked Digital Technologies (NDT)},
  title     = {Classifier Hypothesis Generation Using Visual Analysis Methods},
  year      = {2010},
  editor    = {Filip Zavoral and Jakub Yaghob and Pit Pichappan and Eyas El-Qawasmeh},
  pages     = {98--111},
  publisher = {Springer},
  series    = {Communications in Computer and Information Science},
  volume    = {87},
  abstract  = {Classifiers can be used to automatically dispatch the abundance of newly created documents to recipients interested in particular topics. Identification of adequate training examples is essential for classification performance, but it may prove to be a challenging task in large document repositories. We propose a classifier hypothesis generation method relying on automated analysis and information visualisation. In our approach visualisations are used to explore the document sets and to inspect the results of machine learning methods, allowing the user to assess the classifier performance and adapt the classifier by gradually refining the training set.},
  file      = {:own/Seifert2010a_ndt_classification-and-landscape-published.pdf:PDF},
  isbn      = {978-3-642-14291-8},
  keywords  = {Text Categorisation, Visual Analysis},
  location  = {Heidelberg},
  owner     = {sech},
  timestamp = {2010.07.12},
}

@InProceedings{Seifert2010_eurovast_stress-map-phenomena,
  author    = {Christin Seifert and Vedran Sabol and Wolfgang Kienreich},
  booktitle = {European Symposium Visual Analytics Science and Technology (EuroVAST)},
  title     = {Stress Maps: Analysing Local Phenomena in Dimensionality Reduction Based Visualizations},
  year      = {2010},
  abstract  = {Challenges in Visual Analytics frequently involve massive repositories, which do not only contain a large number of information artefacts, but also a high number of relevant dimensions per artefact. Dimensionality reduction algorithms are commonly used to transform high-dimensional data into low- dimensional representations which are suitable for visualisation purposes. For example, Information Landscapes visualise high-dimensional data in two dimensions using distance-preserving projection methods. The inaccuracies introduced by such methods are usually expressed through a global stress measure which does not provide insight into localised phenomena. In this paper, we propose the use of Stress Maps, a combination of heat maps and information landscapes, to support algorithm development and optimization based on local stress measures. We report on an application of Stress Maps to a scalable text projection algorithm and describe two categories of problems related to localised stress phenomena which we have identified using the proposed method.},
  file      = {:own/Seifert2010_eurovast_stressmaps.pdf:PDF},
  owner     = {sech},
  timestamp = {2010.05.19},
}

@InCollection{Seifert2014_lsda_visual-analysis-and-discovery-for-text,
  author     = {Christin Seifert and Vedran Sabol and Wolfgang Kienreich and Elisabeth Lex and Michael Granitzer},
  booktitle  = {Large Scale Data Analytics},
  publisher  = {Springer},
  title      = {Visual Analysis and Knowledge Discovery for Text},
  year       = {2014},
  editor     = {Aris Gkoulalas-Divanis and Abderrahim Labbi},
  pages      = {189--218},
  abstract   = {Providing means for effectively accessing and exploring large textual data sets is a problem attracting attention of text mining and information visualization experts alike. Rapid growth of the data volume, heterogeneity and richness of metadata, and the dynamic nature of text repositories add to the complexity of the task. This chapter provides an overview of visualization methods for gaining insight into large, heterogeneous, dynamic textual data sets. We argue that visual analysis in combination with automatic knowledge discovery methods provides several advantages. Besides introducing human knowledge and visual pattern recognition into the analytical process, it provides the possibility to improve the performance of automatic methods through user feedback.},
  bdsk-url-1 = {http://link.springer.com/book/10.1007/978-1-4614-9242-9},
  file       = {:own/Seifert2014_bookchapter_visual-text-analysis.pdf:PDF},
  owner      = {sech},
  timestamp  = {2012.01.02},
  url        = {http://link.springer.com/book/10.1007/978-1-4614-9242-9},
}

@TechReport{EEXCESS-D23_first-usability-report,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Andreas Eisenkolb and Cecilia di Sciascio and Vedran Sabol},
  institution = {Know-Center GmbH},
  title       = {{D2.3 -- First Usability Report}},
  year        = {2015},
  type        = {EEXCESS Deliverable},
  file        = {:own/EEXCESS-D23.pdf:PDF},
  owner       = {sech},
  timestamp   = {2015.01.31},
}

@TechReport{EEXCESS-D22_first-componentes-presentation-interfaces,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Andreas Eisenkolb and Cecilia di Sciascio and Vedran Sabol},
  institution = {Know-Center GmbH},
  title       = {{D2.2 -- First Software Components for Presentation and Augmentation Interfaces}},
  year        = {2014},
  type        = {EEXCESS (Restricted) Deliverable},
  file        = {:own/EEXCESS-D22.pdf:PDF},
  owner       = {sech},
  timestamp   = {2014.08.29},
}

@InProceedings{Seifert2015_acmsac_feature-rich-dataset-long-tail-ir,
  author        = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Michael Granitzer},
  booktitle     = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
  title         = {Towards a Feature-Rich Data Set for Personalized Access to Long-Tail Content},
  year          = {2015},
  address       = {New York, NY, USA},
  month         = {4},
  publisher     = {ACM},
  date-added    = {2015-03-05 18:33:57 +0000},
  date-modified = {2015-03-05 18:37:55 +0000},
  file          = {:own/Seifert2015_acmsac_personalised-long-tail-content-eexcess-dataset.pdf:PDF;Presentation:own/Seifert2015_acmsac_personalised-long-tail-content-eexcess-dataset.key:OpenDocument spreadsheet;Presentation:own/Seifert2015_acmsac_personalised-long-tail-content-eexcess-dataset_presentation.pdf:PDF},
}

@InProceedings{Seifert2015c_iv_ui-considerations-browser-based-just-in-time-retrieval,
  author    = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Michael Granitzer},
  booktitle = {Proc. International Conference on Information Visualization (IV)},
  title     = {User Interface Considerations for Browser-Based Just-In-Time Retrieval},
  year      = {2015},
  file      = {:own/Seifert2015b_iv_eexcess-browser-display-styles.pdf:PDF;presentation:own/Seifert2015b_iv_eexcess-browser-display-styles_presentation.pdf:PDF},
  owner     = {sech},
  timestamp = {2015.06.06},
}

@TechReport{EEXCESS-D51_usage-pattern-and-context-detection-specificiation,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Aenne Loehden and Christina Niklaus and Gerhard Doppler and Kim Plassmeier and Henning Manske},
  institution = {University of Passau},
  title       = {{D5.1 -- Usage Pattern and Context Dection Specification and Analysis}},
  year        = {2013},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D51.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.03.20},
}

@TechReport{EEXCESS-D25_final-components-presentation-augmentation-interfaces,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Cecilia di Sciascio and Belgin Mutlu and Gerwald Tschinkel and Peter Hasitschka and Vedran Sabol},
  institution = {Know-Center GmbH},
  title       = {{D2.5 -- Final Software Components for Presentation and Augmentation Interfaces}},
  year        = {2016},
  type        = {EEXCESS (Restricted) Deliverable},
  file        = {:own/EEXCESS-D25.pdf:PDF},
  owner       = {sech},
  timestamp   = {2016.07.24},
}

@TechReport{EEXCESS-D26_second-usability-eval-report,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Cecilia di Sciascio and Belgin Mutlu and Gerwald Tschinkel and Vedran Sabol},
  institution = {Know-Center GmbH},
  title       = {{D2.6 -- Second Usability Evaluation Report}},
  year        = {2016},
  type        = {EEXCESS (Restricted) Deliverable},
  file        = {:own/EEXCESS-D26.pdf:PDF},
  owner       = {sech},
}

@TechReport{EEXCESS-D24_second-software-components-presentation-augmentation,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Cecilia di Sciascio and Belgin Mutlu and Gerwald Tschinklel and Vedran Sabol},
  institution = {Know-Center GmbH},
  title       = {{D2.4 -- Second Software Components for Presentation and Augmentation Interfaces}},
  year        = {2015},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D24.pdf:PDF},
  owner       = {sech},
  timestamp   = {2014.08.29},
}

@TechReport{EEXCESS-D52_first-prototype-user-profile,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Nils Witt and Timo Borst and Sebastian Bayerl and Andreas Eisenkolb},
  institution = {University of Passau},
  title       = {{D5.2 -- First Prototype on User Profile and Context Detection, Usage Analysis Methods and Services}},
  year        = {2014},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D52.pdf:PDF},
  owner       = {sech},
  timestamp   = {2014.08.29},
}

@TechReport{EEXCESS-D53_second-prototype-user-profile-and-context-detection,
  author      = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Nils Witt and Johannes Jurgovsky and Stefan Zwicklbauer},
  institution = {University of Passau},
  title       = {{D5.3 -- Second Prototype on User Profile and Context Detection, Usage Analysis Methods and Services}},
  year        = {2015},
  type        = {EEXCESS Project Deliverable},
  file        = {:own/EEXCESS-D53.pdf:PDF},
  owner       = {sech},
  timestamp   = {2014.08.29},
}

@InProceedings{Seifert2011a_ds_word-clouds-for-efficient-document-labeling,
  author    = {Christin Seifert and Eva Ulbrich and Michael Granitzer},
  booktitle = {The Fourteenth International Conference on Discovery Science},
  title     = {Word Clouds for Efficient Document Labeling},
  year      = {2011},
  address   = {Espoo, Finland},
  month     = oct,
  series    = {DS},
  file      = {:own/Seifert2011a_ds_document-labeling.pdf:PDF},
  owner     = {sech},
  timestamp = {2011.09.27},
}

@Article{Seifert2013_jucs_text-representation-for-efficient-document-annotation,
  author     = {Christin Seifert and Eva Ulbrich and Roman Kern and Michael Granitzer},
  journal    = {Journal of Universal Computer Science},
  title      = {Text Representation for Efficient Document Annotation},
  year       = {2013},
  month      = {2},
  number     = {3},
  pages      = {383--405},
  volume     = {19},
  abstract   = {In text classification the amount and quality of training data is crucial for the performance of the classifier. The generation of training data is done by human labellers - a tedious and time-consuming work. To reduce the labelling time for single documents we propose to use condensed representations of text documents instead of the full-text document. These condensed representations are key sentences and key phrases and can be generated in a fully unsupervised way. We extended and evaluated the TextRank algorithm to automatically extract key sentences and key phrases. For representing key phrases we propose a layout similar to a tag cloud. In a user study with 37 participants we evaluated whether document labelling with these condensed representations can be done faster and equally accurate by the human labellers. Our evaluation shows that the users labelled tag clouds twice as fast and as accurately as full-text documents. While further investigations for different classification tasks are necessary, this insight could potentially reduce costs for the labelling process of text documents.},
  bdsk-url-1 = {http://www.jucs.org/jucs_19_3/text_representation_for_efficient},
  file       = {:own/Seifert2013_jucs_document-labeling.pdf:PDF},
  owner      = {sech},
  timestamp  = {2013.04.26},
  url        = {http://www.jucs.org/jucs_19_3/text_representation_for_efficient},
}

@InProceedings{Seifert2015b_stcn_digital-library-content-in-the-web,
  author     = {Christin Seifert and Nils Witt and Sebastian Bayerl and Michael Granitzer},
  booktitle  = {IEEE STCN Newsletter},
  title      = {Digital Library Content in the Social Web: Resource Usage and Content Injection},
  year       = {2015},
  number     = {1},
  volume     = {3},
  bdsk-url-1 = {https://sites.google.com/a/ieee.net/stc-social-networking/e-letter/stcsn-e-letter-vol-3-no-1/},
  file       = {:own/Seifert2015b_ieee-stcn_digital-library-content-usage-and-injection.pdf:PDF},
  owner      = {sech},
  timestamp  = {2015.06.06},
  url        = {https://sites.google.com/a/ieee.net/stc-social-networking/e-letter/stcsn-e-letter-vol-3-no-1/},
}

@InProceedings{Stoehr2016_icit_web-language-dynamic-content-integration-abstract,
  author     = {Peter St\"{o}hr and Christin Seifert},
  booktitle  = {International Conference on Information Technology \& Computer Science. Abstract Book},
  title      = {Extending the Language of the Web for Dynamic Content Integration},
  year       = {2016},
  bdsk-url-1 = {http://www.atiner.gr/abstracts/2016ABST-COM.pdf},
  owner      = {sech},
  timestamp  = {2016.07.24},
  url        = {http://www.atiner.gr/abstracts/2016ABST-COM.pdf},
}

@InProceedings{Stoehr2016a_atiner_web-language-dynamic-content-integration-abstract,
  author     = {Peter St\"{o}hr and Christin Seifert},
  booktitle  = {Athens: ATINER'S Conference Paper Series},
  title      = {Extending the Language of the Web for Dynamic Content Integration},
  year       = {2016},
  number     = {COM2016-2063},
  bdsk-url-1 = {http://www.atiner.gr/papers/COM2016-2063.pdf},
  file       = {:own/Stoehr2016a_atiner_eexcess-sech-browser.pdf:PDF},
  url        = {http://www.atiner.gr/papers/COM2016-2063.pdf},
}

@InCollection{Stegmaier2014_lncs_unleashing-semantics-of-research-data,
  author     = {Stegmaier, Florian and Seifert, Christin and Kern, Roman and H\"{o}fler, Patrick and Bayerl, Sebastian and Granitzer, Michael and Kosch, Harald and Lindstaedt, Stefanie and Mutlu, Belgin and Sabol, Vedran and Schlegel, Kai and Zwicklbauer, Stefan},
  booktitle  = {Specifying Big Data Benchmarks},
  publisher  = {Springer Berlin Heidelberg},
  title      = {Unleashing Semantics of Research Data},
  year       = {2014},
  editor     = {Rabl, Tilmann and Poess, Meikel and Baru, Chaitanya and Jacobsen, Hans-Arno},
  isbn       = {978-3-642-53973-2},
  pages      = {103-112},
  series     = {Lecture Notes in Computer Science},
  volume     = {8163},
  doi        = {10.1007/978-3-642-53974-9_10},
  file       = {:own/Stegmaier2014_lncs8163_code_unleashing-semantics-of-research-data.pdf:PDF},
  keywords   = {Linked Data; Natural Language Processing; Data Warehousing; Big Data},
  owner      = {sech},
  timestamp  = {2014.02.10},
}

@InProceedings{Stegmaier2012_bdb-ws_unleashing-semantics-of-research-data,
  author    = {Florian Stegmaier and Christin Seifert and Roman Kern and Patrick H\"{o}fler and Sebastian Bayerl and Michael Granitzer and Harald Kosch and Stefanie Lindstaedt and Belgin Mutlu and Vedran Sabol and Kai Schlegel and Stefan Zwicklbauer},
  booktitle = {Proceedings Second Workshop on Big Data Benchmarking},
  title     = {Unleashing Semantics of Research Data},
  year      = {2012},
  address   = {Pune, India},
  month     = {12},
  abstract  = {Research depends to a large degree on the availability and quality of primary research data, i.e., data generated through experiments and evaluations. While the Web in general and Linked Data in particular provide a platform and the necessary technologies for sharing, managing and utilizing research data, an ecosystem supporting those tasks is still missing. The vision of the CODE project is the establishment of a sophisticated ecosystem for Linked Data. Here, the extraction of knowledge encapsulated in scientific research paper along with its public release as Linked Data serves as the major use case. Further, visual analytics approaches empower end users to analyse, integrate and organize data. During these tasks, specific Big Data issues are present.},
  file      = {:own/Stegmaier2012_wdbc_overview-code-project.pdf:PDF},
  owner     = {sech},
  timestamp = {2012.11.02},
}

@InProceedings{VandeVelde2006_its_intelligent-maps-for-vision-enhanced-mobile-interfaces,
  author    = {Linde {Vande Velde} and Patrick Luley and Alexander Almer and Christin Seifert and Lucas Paletta},
  booktitle = {Proc. 12th World Congress on Intelligent Transportation Systems and Services, {ITS} 2006,},
  title     = {Intelligent Maps for Vision Enhanced Mobile Interfaces in Urban Scenarios},
  year      = {2006},
  address   = {London, UK},
  month     = {10},
  abstract  = {This paper focuses on the innovative concept of intelligent digital maps. Event and context information are stored as part of the city maps in order to make the maps intelligent and to exploit further context information of objects. In the EU funded project MOBVIS [10], we develop advanced methodologies to aid mobile vision and context awareness tasks using the enhanced Tele Atlas 2D and 3D City Maps. Augmenting the maps with visual features, semantic and context information enables to support within a given context specifically targeted geoservices in order to deliver appropriate geo-referenced map information on demand. We present preliminary results of geo-indexing the map to retrieve map information in a mobile object recognition task.},
  file      = {:own/VandeVelde2006.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Witt2016_tir_explaining-topical-distances-word-embeddings,
  author    = {Nils Witt and Christin Seifert and Michael Granitzer},
  booktitle = {Proc. International Workshop on Text-based Information Retrieval (TIR)},
  title     = {Explaining Topical Distances Using Word Embeddings},
  year      = {2016},
  address   = {Porto, Portugal},
  month     = {9},
  file      = {:own/Witt2016_tir_topical-distance.pdf:PDF},
  owner     = {sech},
  timestamp = {2016.07.26},
}

@InProceedings{Zwicklbauer2013a_eswc-poster_disambiguating-web-tables,
  author     = {Stefan Zwicklbauer and Christoph Einsiedler and Michael Granitzer and Christin Seifert},
  booktitle  = {International Semantic Web Conference (Posters {\&} Demos)},
  title      = {Towards Disambiguating Web Tables},
  year       = {2013},
  pages      = {205-208},
  bdsk-url-1 = {http://ceur-ws.org/Vol-1035/iswc2013_poster_7.pdf},
  file       = {:own/Zwicklbauer2013a_iswc_table-disambiguation.pdf:PDF;Poster:own/Zwicklbauer2013a_iswc_table-disambiguation_poster.pdf:PDF},
  url        = {http://ceur-ws.org/Vol-1035/iswc2013_poster_7.pdf},
}

@InCollection{Zwicklbauer2015a_smarth-health_linking-biomedical-data-to-the-cloud,
  author     = {Zwicklbauer, Stefan and Seifert, Christin and Granitzer, Michael},
  booktitle  = {Smart Health},
  publisher  = {Springer International Publishing},
  title      = {Linking Biomedical Data to the Cloud},
  year       = {2015},
  editor     = {Holzinger, Andreas and R\"{o}cker, Carsten and Ziefle, Martina},
  isbn       = {978-3-319-16225-6},
  pages      = {209-235},
  series     = {Lecture Notes in Computer Science},
  volume     = {8700},
  doi        = {10.1007/978-3-319-16226-3_9},
  file       = {:own/Zwicklbauer2015a_lncssota8700_biomediacl-entity-disambiguation.pdf:PDF},
  keywords   = {Linked data cloud; Entity disambiguation; Text annotation; Natural language processing; Knowledge bases},
  language   = {English},
  owner      = {sech},
  timestamp  = {2015.06.26},
}

@InProceedings{Zwicklbauer2016_eswc_doser-entity-disambiguation-framwork,
  author    = {Stefan Zwicklbauer and Christin Seifert and Michael Granitzer},
  booktitle = {Proc. European Semantic Web Conference (ESWC)},
  title     = {DoSeR -- A Knowledge-Base-Agnostic Framework for Disambiguating Entities Using Semantic Embeddings},
  year      = {2016},
  file      = {:own/Zwicklbauer2016-eswc-doser.pdf:PDF},
  owner     = {sech},
  timestamp = {2016.02.26},
}

@InProceedings{Zwicklbauer2016a_sigir_doser-entity-disambiguation,
  author    = {Stefan Zwicklbauer and Christin Seifert and Michael Granitzer},
  booktitle = {Proc. International ACM SIGIR Conference on Research and Development in Information Retrieval},
  title     = {Robust and Collective Entity Disambiguation through Semantic Embeddings},
  year      = {2016},
  series    = {SIGIR},
  file      = {:own/Zwicklbauer2016a_sigir_doser.pdf:PDF},
  owner     = {sech},
  timestamp = {2016.04.08},
}

@InProceedings{Zwicklbauer2015_dexa_problems-in-biomedical-entity-disambiguation,
  author    = {Stefan Zwicklbauer and Christin Seifert and Michael Granitzer},
  booktitle = {Proceedings of 26th International Conference on Database and Expert Systems Applications (DEXA)},
  title     = {From General to Specialized Domain: Analyzing Three Crucial Problems of Biomedical Entity Disambiguation},
  year      = {2015},
  publisher = {Springer},
  file      = {:own/Zwicklbauer2015-dexa-biological-disambiguation.pdf:PDF},
  owner     = {sech},
  timestamp = {2015.06.06},
}

@InProceedings{Zwicklbauer2015b_iknow_search-based-entitiy-disambiguation,
  author    = {Stefan Zwicklbauer and Christin Seifert and Michael Granitzer},
  booktitle = {Proceedings of the 14th International Conference on Knowledge Management and Knowledge Technologies (I-Know)},
  title     = {Search-based Entity Disambiguation with Document-Centric Knowledge Bases},
  year      = {2015},
  month     = {10},
  file      = {:own/Zwicklbauer2015b_iknow_search-based-entity-disambiguation.pdf:PDF},
  owner     = {sech},
  timestamp = {2015.08.14},
}

@InProceedings{Zwicklbauer2013_iknow_entity-centric-kbs-for-disambiguation,
  author    = {Stefan Zwicklbauer and Christin Seifert and Michael Granitzer},
  booktitle = {Proceedings of the 13th International Conference on Knowledge Management and Knowledge Technologies (I-Know)},
  title     = {Do we need entity-centric knowledge bases for entity disambiguation?},
  year      = {2013},
  file      = {:own/Zwicklbauer2013_iknow_disambiguation.pdf:PDF},
  owner     = {sech},
  quality   = {1},
  timestamp = {2013.07.10},
}

@InProceedings{Toepfer2017_jcdl_fusion-architectures-subject-indexing,
  author     = {Martin Toepfer and Christin Seifert},
  booktitle  = {Proc. of Joint Conference on Digital Libraries},
  title      = {Descriptor-invariant Fusion Architectures for Automatic Subject Indexing},
  year       = {2017},
  publisher  = {ACM},
  series     = {JCDL},
  addendum   = {\textit{Vannevar Bush Best Paper Nominee}},
  bdsk-url-1 = {http://ieeexplore.ieee.org/abstract/document/7991557/},
  doi        = {10.1109/JCDL.2017.7991557},
  file       = {:PDF:},
  url        = {http://ieeexplore.ieee.org/abstract/document/7991557/},
}

@InProceedings{Seifert2017c_iv_query-crumbs,
  author     = {Christin Seifert and J\"{o}rg Schl\"{o}tterer and Michael Granitzer},
  booktitle  = {Proc. International Conference on Information Visualization (IV)},
  title      = {QueryCrumbs: A Compact Visualization for Navigating the Search Query History},
  year       = {2017},
  note       = {\textbf{Best Paper Award}},
  doi        = {10.1109/iV.2017.23},
  file       = {:own/Seifert2017c_iv_querycrumbs-search-history-vis_preprint.pdf:PDF;:own/Seifert2017c_iv_querycrumbs-search-history-vis_presentation.key:PowerPoint 2007+;:own/Seifert2017c_iv_querycrumbs-search-history-vis_presentation.pdf:PDF},
  owner      = {sech},
  timestamp  = {2017.05.02},
}

@InProceedings{Toepfer2017a_tpdl_semantic-quality-control-subject-indexing,
  author     = {Martin Toepfer and Christin Seifert},
  booktitle  = {Proc. International Conference on Theory and Practice of Digital Libraries (TPDL)},
  title      = {Towards Semantic Quality Control of Automatic Subject Indexing},
  year       = {2017},
  note       = {demo},
  doi        = {10.1007/978-3-319-67008-9 56},
  file       = {:own/Toepfer2017a_tpdl_subject-indexing-gui_preprint.pdf:PDF;Poster:own/Toepfer2017a_tpdl_subject-indexing-gui_poster.pptx:PowerPoint 2007+;Poster:own/Toepfer2017a_tpdl_subject-indexing-gui_poster.pdf:PDF},
  owner      = {sech},
  timestamp  = {2017.06.07},
}

@InProceedings{Witt2017_tpdl_influence-of-hyperparams-text-embeddings,
  author    = {Nils Witt and Christin Seifert},
  booktitle = {Proc. International Conference on Theory and Practice of Digital Libraries (TPDL)},
  title     = {Understanding the Influence of Hyperparameters on Text Embeddings for Text Classification Tasks},
  year      = {2017},
  file      = {:own/Witt2017_tpdl_hyperparameter-understanding_preprint.pdf:PDF},
  owner     = {sech},
  timestamp = {2017.06.07},
}

@InProceedings{Schloetterer2017_cdmake_joint-learning-document-content-network-structure,
  author    = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Michael Granitzer},
  booktitle = {Proc. International Cross Domain Conference for Machine Learning and Knowledge Extraction},
  title     = {On Joint Representation Learning of Network Structure and Document Content},
  year      = {2017},
  file      = {preprint:own/Schloetterer2017_cdmake_Joint-Representation-Learning_preprint.pdf:PDF},
}

@Misc{Seifert2017d_trust-worthy-dm_contextualized-personalized-explanations-ml_vision,
  author       = {Christin Seifert},
  title        = {Contextialized and personalized explanations of machine learning algorithms},
  year         = {2017},
  booktitle    = {Workshop on Trustworthy Algorithmic Decision-Making},
  file         = {own/Seifert2017d_ws-trustworthy-algos_explanations-of-algos.pdf},
  organization = {Michigan State University},
}

@InProceedings{Witt2018_ecir_collection-document-summaries,
  author    = {Witt, Nils and Granitzer, Michael and Seifert, Christin},
  booktitle = {Advances in Information Retrieval},
  title     = {Collection-Document Summaries},
  year      = {2018},
  address   = {Cham},
  editor    = {Pasi, Gabriella and Piwowarski, Benjamin and Azzopardi, Leif and Hanbury, Allan},
  pages     = {638--643},
  publisher = {Springer International Publishing},
  abstract  = {Learning something new from a text requires the reader to build on existing knowledge and add new material at the same time. Therefore, we propose collection-document (CDS) summaries that highlight commonalities and differences between a collection (or a single document) and a single document. We devise evaluation metrics that do not require human judgement, and three algorithms for extracting CDS that are based on single-document keyword-extraction methods. Our evaluation shows that different algorithms have different strengths, e.g. TF-IDF based approach best describes document overlap while the adaption of Rake provides keywords with a broad topical coverage. The proposed criteria and procedure can be used to evaluate document-collection summaries without annotated corpora or provide additional insight in an evaluation with human-generated ground truth.},
  file      = {:own/Witt2018_ecir_document-collection-summaries.pdf:PDF;:own/Witt2018_ecir_document-collection-summaries_poster.pdf:PDF},
  isbn      = {978-3-319-76941-7},
  owner     = {sech},
  timestamp = {2018.04.17},
}

@Article{Toepfer2018_ijdl_fusion-architectures-subject-indexing,
  author   = {Toepfer, Martin and Seifert, Christin},
  journal  = {International Journal on Digital Libraries},
  title    = {Fusion architectures for automatic subject indexing under concept drift},
  year     = {2018},
  issn     = {1432-1300},
  month    = may,
  abstract = {Indexing documents with controlled vocabularies enables a wealth of semantic applications for digital libraries. Due to the rapid growth of scientific publications, machine learning-based methods are required that assign subject descriptors automatically. While stability of generative processes behind the underlying data is often assumed tacitly, it is being violated in practice. Addressing this problem, this article studies explicit and implicit concept drift, that is, settings with new descriptor terms and new types of documents, respectively. First, the existence of concept drift in automatic subject indexing is discussed in detail and demonstrated by example. Subsequently, architectures for automatic indexing are analyzed in this regard, highlighting individual strengths and weaknesses. The results of the theoretical analysis justify research on fusion of different indexing approaches with special consideration on information sharing among descriptors. Experimental results on titles and author keywords in the domain of economics underline the relevance of the fusion methodology, especially under concept drift. Fusion approaches outperformed non-fusion strategies on the tested data sets, which comprised shifts in priors of descriptors as well as covariates. These findings can help researchers and practitioners in digital libraries to choose appropriate methods for automatic subject indexing, as is finally shown by a recent case study.},
  day      = {15},
  doi      = {10.1007/s00799-018-0240-3},
  file     = {:own-pdf/Toepfer2018_ijdl_subject-indexing-under-concept-drift_preprint.pdf:PDF},
}

@InProceedings{Milz2018_tir-ws_author-self-citations-in-CS,
  author    = {Tobias Milz and Christin Seifert},
  booktitle = {Proc. International Workshop on Technologies for Information Retrieval (TIR)},
  title     = {Analysing Author Self-Citations in Computer Science Publications},
  year      = {2018},
}

@InProceedings{Toepfer2018a_tpdl_subject-indexing-quality-estimation,
  author    = {Martin Toepfer and Christin Seifert},
  booktitle = {Proc. International Conference on Theory and Practice of Digital Libraries (TPDL)},
  title     = {Content-Based Quality Estimation for Automatic Subject Indexing of Short Texts under Precision and Recall Constraints},
  year      = {2018},
  file      = {:own/Toepfer2018a_tpdl_quality-estimation_archive-preprint.pdf:PDF},
  url       = {https://arxiv.org/abs/1806.02743},
}

@InProceedings{Milz2018a_tpdl_citation-patterns-in-CS,
  author    = {Tobias Milz and Christin Seifert},
  booktitle = {Proc. International Conference on Theory and Practice of Digital Libraries (TPDL)},
  title     = {Who cites what in Computer Science? - Analysing Citation Patterns across Conference Rank and Gender},
  year      = {2018},
  file      = {:own/Milz2018_tpdl_citation-rank-gender_preprint.pdf:PDF},
}

@InProceedings{Witt2018a_ds_keyphrase-scoring,
  author    = {Nils Witt and Tobias Milz and Christin Seifert},
  booktitle = {Proc. International Conference on Discovery Science},
  title     = {Most Important First  Keyphrase Scoring for Improved Ranking in Settings With Limited Keyphrases},
  year      = {2018},
  series    = {DS},
  file      = {:own/Witt2018a_ds_keyphrase-scoring_preprint.pdf:PDF;:own.bib:bib},
  owner     = {sech},
  timestamp = {2018.09.15},
}

@InProceedings{Pathak2018_dmbih-ws_structuring-breast-cancer-radiology-reports,
  author    = {Shreyasi Pathak and Jorit {van Rossen} and Onno Vijlbrief and Jeroen Geerdink and Christin Seifert and Maurice {van Keulen}},
  booktitle = {Proc. Workshop on Data Mining in Biomedical Informatics and Healthcare},
  title     = {Automatic Structuring of Breast Cancer Radiology Reports for Quality Assurance},
  year      = {2018},
  series    = {DMBIH},
  file      = {:own/Pathak2018-dmbih-radiology-report-structuring.pdf:PDF},
  owner     = {sech},
  timestamp = {2018.09.15},
}

@Article{Nauta2019_mdpi-make_causal-discovery-tcdf,
  author   = {Nauta, Meike and Bucur, Doina and Seifert, Christin},
  journal  = {Machine Learning and Knowledge Extraction},
  title    = {Causal Discovery with Attention-Based Convolutional Neural Networks},
  year     = {2019},
  issn     = {2504-4990},
  month    = jan,
  number   = {1},
  pages    = {312--340},
  volume   = {1},
  abstract = {Having insight into the causal associations in a complex system facilitates decision making, e.g., for medical treatments, urban infrastructure improvements or financial investments. The amount of observational data grows, which enables the discovery of causal relationships between variables from observation of their behaviour in time. Existing methods for causal discovery from time series data do not yet exploit the representational power of deep learning. We therefore present the Temporal Causal Discovery Framework (TCDF), a deep learning framework that learns a causal graph structure by discovering causal relationships in observational time series data. TCDF uses attention-based convolutional neural networks combined with a causal validation step. By interpreting the internal parameters of the convolutional networks, TCDF can also discover the time delay between a cause and the occurrence of its effect. Our framework learns temporal causal graphs, which can include confounders and instantaneous effects. Experiments on financial and neuroscientific benchmarks show state-of-the-art performance of TCDF on discovering causal relationships in continuous time series data. Furthermore, we show that TCDF can circumstantially discover the presence of hidden confounders. Our broadly applicable framework can be used to gain novel insights into the causal dependencies in a complex system, which is important for reliable predictions, knowledge discovery and data-driven decision making.},
  comment  = {paper with code https://paperswithcode.com/paper/causal-discovery-with-attention-based-co},
  doi      = {10.3390/make1010019},
  url      = {http://www.mdpi.com/2504-4990/1/1/19},
}

@Article{Pathak2019_tcbb_post-structuring-radiology-reports,
  author   = {Shreyasi Pathak and Jorit {van Rossen} and Onno Vijlbrief and Jeroen Geerdink and Christin Seifert and Maurice {van Keulen}},
  journal  = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  title    = {Post-Structuring Radiology Reports of Breast Cancer Patients for Clinical Quality Assurance},
  year     = {2019},
  issn     = {2375-9259},
  month    = may,
  doi      = {10.1109/TCBB.2019.2914678},
  file     = {:own/Pathak2019_tcbb_post-structuring-radiology-reports_preprint.pdf:PDF},
  keywords = {Radiology;Breast cancer;Quality assurance;Standards;Task analysis;Machine learning;Natural language processing;Quality Assurance;Automatic Structuring;Post-Structuring;Radiology Reports;Conditional Random Field},
}

@InProceedings{Scherzinger2019_ieee-icdcs_distributed-ml-provenance-explainability,
  author    = {Stefanie Scherzinger and Christin Seifert and Lena Wiese},
  booktitle = {Proc. International Conference on Distributed Computing Systems},
  title     = {The Best of both Worlds: Challenges in Linking Provenance and Explainability in Distributed ML},
  year      = {2019},
  series    = {ICDCS},
  file      = {:own/Scherzinger2019_icdcs_e2e-explanations_preprint.pdf:PDF},
}

@InProceedings{Papenmeier2019_ijcai-xai-ws_trust-explanations-accuracy,
  author    = {Andrea Papenmeier and Gwenn Englebienne and Christin Seifert},
  booktitle = {IJCAI Workshop on Explainable Artificial Intelligence (X-AI)},
  title     = {How model accuracy and explanation fidelity influence user trust in AI},
  year      = {2019},
  note      = {\textbf{Best Paper Award}},
  comment   = {submitted},
  url       = {http://arxiv.org/abs/1907.12652},
}

@InProceedings{Marazza2019_pods-ws_process-model-comparison-breast-cancer,
  author    = {Francesca Marazza and Faiza Bukhsh and Onno Vijlbrief and Jeroen Geerdink and Shreyaasi Pathak and Maurice van Keulen and Christin Seifert},
  booktitle = {Proc. International Workshop on Process-Oriented Data Science for Healthcare},
  title     = {Comparing Process Models for Patient Populations: Application in Breast Cancer Care},
  year      = {2019},
  file      = {:own/Marazza2019_pods_Process-Models-Breast-Cancer-Care_preprint.pdf:PDF},
}

@InProceedings{Theodorus2019_icmv_cnn-interpretability-sketch,
  author    = {Abraham Theodorus and Meike Nauta and Christin Seifert},
  booktitle = {Proc. International Conference on Machine Vision},
  title     = {Evaluating CNN Interpretabilty on Sketch Classification},
  year      = {2019},
  doi       = {10.1117/12.2559536},
  file      = {:own/Theodorus2019_icmv_cnn-interpretability-on-sketch-data_author-copy.pdf:PDF;:own/Theodorus2019_icmv_cnn-interpretability-on-sketch-data_publisher-version.pdf:PDF},
}

@InProceedings{Peters2019_bcai_visualizing-training-nn-lay,
  author    = {Michelle Peters and Lindsay Kempen and Meike Nauta and Christin Seifert},
  booktitle = {Proc. Benelux Conference on Artificial Intelligence},
  title     = {Visualising the Training Process of Convolutional Neural Networks for Non-Experts},
  year      = {2019},
  series    = {BNAIC},
  file      = {:own/Peters2019_bnaic-vis-training-cnn_author-copy.pdf:PDF},
  url       = {http://ceur-ws.org/Vol-2491/},
}

@InProceedings{Seifert2019_ieee-cogmi_consumper-labels,
  author    = {Christin Seifert and Stefanie Scherzinger and Lena Wiese},
  booktitle = {Proc. International Conference on Cognitive Machine Intelligence},
  title     = {Towards Generating Consumer Labels for Machine Learning Models},
  year      = {2019},
  series    = {CogMI},
  file      = {:own/Seifert2019_cogmi_consumer-labels_preprint.pdf:PDF},
}

@InProceedings{Ros2019_ieee-cic_airport-restroom-cleanliness,
  author    = {Kilian Ros and Elena Mocanu and Christin Seifert},
  booktitle = {Proc. International Conference on Collaboration and Internet Computing},
  title     = {Airport Restroom Cleanliness Prediction Using Real Time User Feedback Data},
  year      = {2019},
  series    = {CIC},
  file      = {:own/Ros2019_cogmi_airport_restroom_cleanliness_preprint.pdf:PDF},
}

@InProceedings{Trienes2020_hsdm-ws_de-identification-dutch-medical,
  author    = {Jan Trienes and Dolf Trieschnigg and Christin Seifert and Djoerd Hiemstra},
  booktitle = {Proc. Health Search and Data Mining Workshop},
  title     = {Comparing Rule-based, Feature-based and Deep Neural Methods for De-identification of Dutch Medical Records},
  year      = {2020},
  series    = {HSDM},
  addendum  = {\textit{Best Paper Award}},
  file      = {:own-pdf/Trienes2020_hsdm_anonymizing-health-records_preprint.pdf:PDF},
}

@Article{vanKeulen2020_bjds_data-science-teaching-at-UT,
  author   = {Maurice {van Keulen} and Christin Seifert and Mannes Poel and Karin Groothuis-Oudshoorn},
  journal  = {Berlin Journal of Data Science},
  title    = {Scalable Interdisciplinary Data Science Teaching at the University of Twente},
  year     = {2020},
  issn     = {978-3-00-064614-0},
  month    = {12},
  volume   = {1},
  abstract = {Data scientists are in high demand in many disciplines and domains. This paper describes the data science course open to all master students of the University of Twente. We outline the main challenges of teaching a large and heterogeneous population of non-computer science students about data science and how we addressed them, as well as a historical perspective on how the course grew and evolved.},
  language = {English},
  url      = {http://data-science-berlin.de/posts/01/scalable-interdisciplinary-data-science-teaching-at-the-university-of-twente.pdf},
}

@Article{Schloetterer2020_jcl_query-crumbs,
  author    = {J\"{o}rg Schl\"{o}tterer and Christin Seifert and Michael Granitzer},
  journal   = {Journal of Computer Languages},
  title     = {QueryCrumbs Search History Visualization - Usability, Transparency and Long-term Usage},
  year      = {2020},
  issn      = {2590-1184},
  volume    = {57},
  abstract  = {Models of human information seeking reveal that search, in particular ad-hoc retrieval, is non-linear and iterative. Despite these findings, todays search user interfaces do not support non-linear navigation, like for example backtracking in time. We propose QueryCrumbs, a compact and easy-to-understand visualization for navigating the search query history supporting iterative query refinement. We apply a multi-layered interface design to support novices and first-time users as well as intermediate and expert users. The visualization is evaluated with novice users in a formative user study, with experts in a think aloud test and its usage in a long-term study with software logging. The formative evaluation showed that the interactions can be easily performed, and the visual encodings were well understood without instructions. Results indicate that QueryCrumbs can support users when searching for information in an iterative manner. The evaluation with experts showed that expert users can gain valuable insights into the back-end search engine by identifying specific patterns in the visualization. In a long-term usage study, we observed an uptake of the visualization, indicating that users deem QueryCrumbs beneficial for their search interactions.},
  doi       = {10.1016/j.cola.2020.100941},
  file      = {:own/Schloetterer2020_jcl_querycrumbs_author-version.pdf:PDF},
  owner     = {sech},
  timestamp = {2020.01.03},
  url       = {http://www.sciencedirect.com/science/article/pii/S2590118420300010},
}

@InProceedings{Legoy2020_cti-symp_cyberthread-report-text-analysis,
  author    = {Valentine Legoy and Marco Caselli and Andreas Peter and Christin Seifert},
  booktitle = {FIRST Cyber Threat Intelligence Symposium},
  title     = {rcATT: retrieving ATT\&CK tactics and techniques in cyber threat reports},
  year      = {2020},
  address   = {Zurich},
  month     = mar,
  file      = {:own/Legoy2020_arxiv_attack-classification.pdf:PDF},
  owner     = {sech},
  timestamp = {2020.01.03},
}

@Article{Marazza2020_mdpi-jerph_process-comparison-cancer,
  author  = {Francesca Marazza and Faiza Allah Bukhsh and Jeroen Geerdink and Onno Vijlbrief and Shreyasi Pathak and Maurice van Keulen and Christin Seifert},
  journal = {Int. J. Environ. Res. Public Health},
  title   = {Automatic Process Comparison for Subpopulations: Application in Cancer Care},
  year    = {2020},
  number  = {16},
  volume  = {17},
  doi     = {10.3390/ijerph1716570},
  file    = {:own/Marazza2020_ijerph_process-comparison-cancer-care_preprint.pdf:PDF},
  url     = {https://www.mdpi.com/1660-4601/17/16/5707/htm},
}

@InProceedings{Nauta2020_kdh-ws_interactive-explanations-comatose-patients,
  author    = {Meike Nauta and Michel J.A.M. {van Putten} and Marleen C. Tjepkema-Cloostermans and Jeroen Peter Bos and Maurice {van Keulen} and Christin Seifert},
  booktitle = {International Workshop on Knowledge Discovery in Healthcare Data},
  title     = {Interactive Explanations of Internal Representations of Neural Network Layers: An Exploratory Study on Outcome Prediction of Comatose Patients},
  year      = {2020},
  series    = {KDH},
  volume    = {2675},
  file      = {:own/Nauta2019_make_causal-discovery_preprint.pdf:PDF},
  url       = {http://ceur-ws.org/Vol-2675/paper1.pdf},
}

@InProceedings{Marin2020_ieeesmc_word-prediction-mammography,
  author    = {Mihai David Marin and Elena Mocanu and Christin Seifert},
  booktitle = {Proc. IEEE International Conference on Systems, Man, and Cybernetics},
  title     = {Effectiveness of neural language models for word prediction of textual mammography reports},
  year      = {2020},
  series    = {IEEE SMC},
  file      = {:/Volumes/Data/data-work/research/literature/bib/own/Marin2020_SMC_Language-Models-for-mammography-reports_preprint.pdf:PDF},
}

@InProceedings{Ruis2020_icdm-dmbih-ws_medication-extraction,
  author    = {Frank Ruis and Shreyasi Pathak and Jeroen Geerdink and Johannes H. Hegeman and Christin Seifert and Maurice van Keulen},
  booktitle = {Proc. International Conference on Data Mining Workshops},
  title     = {Human-in-the-loop Language-agnostic Extraction of Medication Data from Highly Unstructured Electronic Health Records},
  year      = {2020},
  publisher = {{IEEE}},
  file      = {:/Volumes/Data/data-work/research/literature/bib/own/Ruis2020_dmbih_medication_extraction_preprint.pdf:PDF;:own-pdf/Ruis2020human_in_the_loop_preprint.pdf:PDF},
}

@InProceedings{Nguyen2020_ieeecogmi_summarization-breast-cancer-radiology-reports,
  author    = {Elisa Nguyen and Daphne Theodorakopoulos and Shreyasik Pathak and Jeroen Geerdink and Onno Vijlbrief and Maurice {van Keulen} and Christin Seifert},
  booktitle = {Proceedings International Conference on Cognitive Machine Intelligence},
  title     = {A Hybrid Text Classification and Language Generation Model for Automated Summarization of Dutch Breast Cancer Radiology Reports},
  year      = {2020},
  publisher = {IEEE},
  series    = {CogMI},
  file      = {:/Volumes/Data/data-work/Research/Literature/bib/own/Nguyen2020_cogmi_automatic-report-summarization_preprint.pdf:PDF},
}

@Article{Vries2021_osteoporosis_risk-assessment-for-future-fractures,
  author   = {Bram C. S. {de Vries} and Johannes H. Hegeman and Wieke Nijmeijer and Jeroen Geerdink and Christin Seifert and Karin G. M. Groothuis-Oudshoorn},
  journal  = {Osteoporosis International},
  title    = {Comparing three machine learning approaches to design a risk assessment tool for future fractures: predicting a subsequent major osteoporotic fracture in fracture patients with osteopenia and osteoporosis},
  year     = {2021},
  issn     = {1433-2965},
  month    = jan,
  abstract = {Four machine learning models were developed and compared to predict the risk of a future major osteoporotic fracture (MOF), defined as hip, wrist, spine and humerus fractures, in patients with a prior fracture. We developed a user-friendly tool for risk calculation of subsequent MOF in osteopenia patients, using the best performing model.},
  doi      = {10.1007/s00198-020-05735-z},
  file     = {:/Volumes/Data/data-work/Research/Literature/bib/own/Vries2021_OstInt_ComparingThreeMachineLearningA.pdf:PDF;:/Volumes/Data/data-work/Research/Literature/bib/own/Vries2021_ostint_predicting-subsequent-fracture_author-version.pdf:PDF},
}

@InProceedings{Nauta2021_cvpr_prototree,
  author    = {Meike Nauta and Ron van Bree and Christin Seifert},
  booktitle = {{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}},
  title     = {Neural Prototype Trees for Interpretable Fine-grained Image Recognition},
  year      = {2021},
  pages     = {14933--14943},
  file      = {:own-pdf/Nauta2021_cvpr_ProtoTree_proceedings-version.pdf:PDF},
}

@Article{Pathak2021_aim_automatic-sleep-scoring,
  author   = {Shreyasi Pathak and Changqing Lu and Sunil Belur Nagaraj and Michel {van Putten} and Christin Seifert},
  journal  = {Artificial Intelligence in Medicine},
  title    = {{STQS: Interpretable multi-modal Spatial-Temporal-seQuential model for automatic Sleep scoring}},
  year     = {2021},
  issn     = {0933-3657},
  pages    = {102038},
  volume   = {114},
  doi      = {10.1016/j.artmed.2021.102038},
  file     = {:/Volumes/Data/data-work/Research/Literature/bib/own/Pathak2021_aim_STQS-interpretable-model-for-sleep-scoring_preprint.pdf:PDF},
  keywords = {Sleep scoring, Sleep stage annotation, Deep learning, EEG, EOG, EMG signals, Post-hoc interpretability, Explainable AI},
  url      = {https://www.sciencedirect.com/science/article/pii/S0933365721000312},
}

@Article{Libbi2021_futint_synthetic-data-deidentification,
  author         = {Libbi, Claudia Alessandra and Trienes, Jan and Trieschnigg, Dolf and Seifert, Christin},
  journal        = {Future Internet},
  title          = {Generating Synthetic Training Data for Supervised De-Identification of Electronic Health Records},
  year           = {2021},
  issn           = {1999-5903},
  number         = {5},
  volume         = {13},
  abstract       = {A major hurdle in the development of natural language processing (NLP) methods for Electronic Health Records (EHRs) is the lack of large, annotated datasets. Privacy concerns prevent the distribution of EHRs, and the annotation of data is known to be costly and cumbersome. Synthetic data presents a promising solution to the privacy concern, if synthetic data has comparable utility to real data and if it preserves the privacy of patients. However, the generation of synthetic text alone is not useful for NLP because of the lack of annotations. In this work, we propose the use of neural language models (LSTM and GPT-2) for generating artificial EHR text jointly with annotations for named-entity recognition. Our experiments show that artificial documents can be used to train a supervised named-entity recognition model for de-identification, which outperforms a state-of-the-art rule-based baseline. Moreover, we show that combining real data with synthetic data improves the recall of the method, without manual annotation effort. We conduct a user study to gain insights on the privacy of artificial text. We highlight privacy risks associated with language models to inform future research on privacy-preserving automated text generation and metrics for evaluating privacy-preservation during text generation.},
  article-number = {136},
  doi            = {10.3390/fi13050136},
  file           = {:own-pdf/Libbi2021-SyntheticTrainingData_preprint.pdf:PDF},
  url            = {https://www.mdpi.com/1999-5903/13/5/136},
}

@InProceedings{Nauta2021a_xkdd_explaining-prototypes,
  author    = {Meike Nauta and Annemarie Jutte and Jesper Provoost and Christin Seifert},
  booktitle = {Proc. ECML PKDD International Workshop on eXplainable Knowledge Discovery in Data Mining (XKDD)},
  title     = {This Looks Like That, Because ... Explaining Prototypes for Interpretable Image Recognition},
  year      = {2021},
  file      = {:own/Nauta2021a_xkdd_exproto_author-version.pdf:PDF},
  url       = {https://arxiv.org/abs/2011.02863},
}

@InCollection{Liu2021a_tsd_rewriting-fiction,
  author    = {Dou Liu and Tingting Zhu and Jrg Schltterer and Christin Seifert and Shenghui Wang},
  booktitle = {Text, Speech, and Dialogue},
  publisher = {Springer International Publishing},
  title     = {Rewriting Fictional Texts Using Pivot Paraphrase Generation and Character Modification},
  year      = {2021},
  pages     = {73--85},
  doi       = {10.1007/978-3-030-83527-9_6},
  file      = {:own/Dou2021_tsd_rewriting-fictional-texts_preprint.pdf:PDF},
}

@InProceedings{Nauta2021b_beyondfairws_prototree,
  author    = {Meike Nauta and Ron van Bree and Christin Seifert},
  booktitle = {Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision: CVPR 2021 Workshop},
  title     = {Intrinsically Interpretable Image Recognition with Neural Prototype Trees},
  year      = {2021},
  file      = {:own-pdf/Nauta2021c_cvpr-ws_prototree_author-version.pdf:PDF},
}

@Article{Nauta2022_diagnostics_short-cut-learning-skin-cancer,
  author         = {Nauta, Meike and Walsh, Ricky and Dubowski, Adam and Seifert, Christin},
  journal        = {Diagnostics},
  title          = {Uncovering and Correcting Shortcut Learning in Machine Learning Models for Skin Cancer Diagnosis},
  year           = {2022},
  issn           = {2075-4418},
  number         = {1},
  volume         = {12},
  abstract       = {Machine learning models have been successfully applied for analysis of skin images. However, due to the black box nature of such deep learning models, it is difficult to understand their underlying reasoning. This prevents a human from validating whether the model is right for the right reasons. Spurious correlations and other biases in data can cause a model to base its predictions on such artefacts rather than on the true relevant information. These learned shortcuts can in turn cause incorrect performance estimates and can result in unexpected outcomes when the model is applied in clinical practice. This study presents a method to detect and quantify this shortcut learning in trained classifiers for skin cancer diagnosis, since it is known that dermoscopy images can contain artefacts. Specifically, we train a standard VGG16-based skin cancer classifier on the public ISIC dataset, for which colour calibration charts (elliptical, coloured patches) occur only in benign images and not in malignant ones. Our methodology artificially inserts those patches and uses inpainting to automatically remove patches from images to assess the changes in predictions. We find that our standard classifier partly bases its predictions of benign images on the presence of such a coloured patch. More importantly, by artificially inserting coloured patches into malignant images, we show that shortcut learning results in a significant increase in misdiagnoses, making the classifier unreliable when used in clinical practice. With our results, we, therefore, want to increase awareness of the risks of using black box machine learning models trained on potentially biased datasets. Finally, we present a model-agnostic method to neutralise shortcut learning by removing the bias in the training dataset by exchanging coloured patches with benign skin tissue using image inpainting and re-training the classifier on this de-biased dataset.},
  article-number = {40},
  doi            = {10.3390/diagnostics12010040},
  file           = {:own-pdf/Nauta2022_diagnostics_Correcting-Shortcut-Learning-Skin-Cancer_author-version.pdf:PDF},
  url            = {https://www.mdpi.com/2075-4418/12/1/40},
}

@Article{Papenmeier2022_tochi_trust-accuracy-explanations,
  author     = {Papenmeier, Andrea and Kern, Dagmar and Englebienne, Gwenn and Seifert, Christin},
  journal    = {ACM Trans. Comput.-Hum. Interact.},
  title      = {{Its Complicated: The Relationship between User Trust, Model Accuracy and Explanations in AI}},
  year       = {2022},
  issn       = {1073-0516},
  month      = {mar},
  number     = {4},
  volume     = {29},
  abstract   = {Automated decision-making systems become increasingly powerful due to higher model complexity. While powerful in prediction accuracy, Deep Learning models are black boxes by nature, preventing users from making informed judgments about the correctness and fairness of such an automated system. Explanations have been proposed as a general remedy to the black box problem. However, it remains unclear if effects of explanations on user trust generalise over varying accuracy levels. In an online user study with 959 participants, we examined the practical consequences of adding explanations for user trust: We evaluated trust for three explanation types on three classifiers of varying accuracy. We find that the influence of our explanations on trust differs depending on the classifiers accuracy. Thus, the interplay between trust and explanations is more complex than previously reported. Our findings also reveal discrepancies between self-reported and behavioural trust, showing that the choice of trust measure impacts the results.},
  address    = {New York, NY, USA},
  articleno  = {35},
  doi        = {10.1145/3495013},
  file       = {:own-pdf/Papenmeier2022_tochi_xai-trust-accuracy_preprint.pdf:PDF},
  issue_date = {August 2022},
  keywords   = {minimum explanations, explanation fidelity, user trust, machine learning, Explainable AI},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{Schmidt2021_ieeecogmi_essen-medical-computing-platform,
  author    = {Schmidt, Hendrik F.R. and Schl{\"o}tterer, J{\"o}rg and Bargull, Marcel and Nasca, Enrico and Aydelott, Ryan and Seifert, Christin and Meyer, Folker},
  booktitle = {{{IEEE}} International Conference on Cognitive Machine Intelligence ({{CogMI}})},
  title     = {Towards a Trustworthy, Secure and Reliable Enclave for Machine Learning in a Hospital Setting: {{The Essen Medical Computing Platform}} ({{EMCP}})},
  year      = {2021},
  pages     = {116--123},
  doi       = {10.1109/CogMI52975.2021.00023},
  file      = {:own/Schmidt2021_cogmi_ML-in-hospital_preprint.pdf:PDF},
}

@InProceedings{Zerhoudi2022_ecir_evaluating-user-behaviour-in-ir,
  author    = {Zerhoudi, Saber and Granitzer, Michael and Seifert, Christin and Schloetterer, Joerg},
  booktitle = {Advances in Information Retrieval},
  title     = {Evaluating Simulated User Interaction and Search Behaviour},
  year      = {2022},
  address   = {Cham},
  editor    = {Hagen, Matthias and Verberne, Suzan and Macdonald, Craig and Seifert, Christin and Balog, Krisztian and N{\o}rv{\aa}g, Kjetil and Setty, Vinay},
  pages     = {240--247},
  publisher = {Springer International Publishing},
  abstract  = {Simulating user sessions in a way that comes closer to the original user interactions is key to generating user data at any desired volume and variety such that A/B-testing in domain-specific search engines becomes scalable. In recent years, research on evaluating Information Retrieval (IR) systems has mainly focused on simulation as means to improve users models and evaluation metrics about the performance of search engines using test collections and user studies. However, test collections contain no user interaction data and user studies are expensive to conduct. Thus there is a need in developing a methodology for evaluating simulated user sessions. In this paper, we propose evaluation metrics to assess the realism of simulated sessions and describe a pilot study to assess the capability of generating simulated search sequences representing an approximation of real behaviour. Our findings highlight the importance of investigating and utilising classification-based metrics besides the distribution-based ones in the evaluation process.},
  doi       = {10.1007/978-3-030-99739-7\_28},
  file      = {:own-pdf/Zerhoudi2022a_ircdl_simulating-user-behavior_preprint.pdf:PDF},
  isbn      = {978-3-030-99739-7},
}

@InProceedings{Zerhoudi2021_fire_simulating-search-behaviour-with-query-change,
  author    = {Saber Zerhoudi and Michael Granitzer and J\"{o}rg Schl\"{o}tterer and Christin Seifert},
  booktitle = {Proceedings of the 12th Forum for Information Retrieval Evaluation},
  title     = {Query Change as a Contextual Markov Model for Simulating User Search Behaviour},
  year      = {2021},
  publisher = {Association for Computing Machinery},
  series    = {FIRE '21},
  abstract  = {Search engine users issue queries to formulate their information need and gain useful insights. However, it is challenging for search engines to understand different users search type intents and re- turn appropriate results. Simulating user search behaviour allows information retrieval systems (IR) to parameterise the a-priori dis- tribution of search types using different back-end configurations and user interface variants to improve the retrieval functionality. In this paper, we propose a formal Markov approach in which we utilise the context discovery process to model user-type specific behaviour by capturing the users query change in a search session. Contextual Markov models have been used in the past to improve the prediction of user intentions, we investigate here their effi- ciency in simulating user-type specific interactions. Additionally, we provide an empirical and classification-based evaluation that can be used in simulation assessment. Overall, we report that the proposed approach reliably simulates user-type specific behaviour on a real-world academic search engine log dataset.},
  doi       = {10.1145/3503162.3503165},
  file      = {:own-pdf/Zerhoudi2021_fire_simulating-user-search.pdf:PDF},
}

@InProceedings{Papenmeier2022a_chi_percevied-accuracy,
  author    = {Andrea Papenmeier and Dagmar Kern and Daniel Hienert and Yvonne Kammerer and Christin Seifert},
  booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  title     = {{How Accurate Does It Feel? -- Human Perception of Different Types of Classification Mistakes}},
  year      = {2022},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CHI '22},
  doi       = {10.1145/3491102.3501915},
  file      = {:own-pdf/Papenmeier2022a_chi_percevied-accuracy_preprint.pdf:PDF},
}

@InProceedings{Ali2007a_oeagm-ws_window-detection-in-facades,
  author    = {Haider Ali and Christin Seifert and Nitin Jindal and Lucas Paletta and Gerhard Paar},
  booktitle = {Proc. 31st Workshop of the Austrian Association for Pattern Recognition},
  title     = {Learning to Detect Windows in Urban Environments},
  year      = {2007},
  address   = {Krumbach, Austria},
  pages     = {73--80},
  file      = {Ali2007a.pdf:own/Ali2007a.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Ali2007_iciap_window-detection-in-facades,
  author    = {Haider Ali and Christin Seifert and Nitin Jindal and Lucas Paletta and Gerhard Paar},
  booktitle = {14th International Conference on Image Analysis and Processing (ICIAP 2007)},
  title     = {Window Detection in Facades},
  year      = {2007},
  editor    = {Rita Cucchiara},
  pages     = {837--842},
  publisher = {IEEE Computer Society},
  abstract  = {This work is about a novel methodology for window detection in urban environments and its multiple use in vision system applications. The presented method for window detection includes appropriate early image processing, provides a multi-scale Haar wavelet representation for the determination of image tiles which is then fed into a cascaded classifier for the task of window detection. The classifier is learned from a Gentle Adaboost driven cascaded decision tree [1] on masked information from training imagery and is tested towards window based ground truth information which is - together with the original building image databases - publicly available [10, 11, 13]. The experimental results demonstrate that single window detection is to a sufficient degree successful, e.g., for the purpose of building recognition, and, furthermore, that the classifier is in general capable to provide a region of interest operator for the interpretation of urban environments. The extraction of this categorical information is beneficial to index into search spaces for urban object recognition as well as aiming towards providing a semantic focus for accurate post-processing in 3D information processing systems. Targeted applications are (i) mobile services on uncalibrated imagery, e.g. , for tourist guidance, (ii) sparse 3D city modeling, and (iii) deformation analysis from high resolution imagery.},
  file      = {Ali2007.pdf:own/Ali2007.pdf:PDF},
  owner     = {sech},
  timestamp = {2007.11.04},
}

@InProceedings{Zerhoudi2022a_ircdl_simulating-user-behavior,
  author    = {Saber Zerhoudi and Michael Granitzer and Christin Seifert and J\"{o}rg Schl"{o}tterer},
  booktitle = {Proc. Italian Research Conference on Digital Libraries},
  title     = {Simulating User Interaction and Search Behaviour in Digital Libraries},
  year      = {2022},
  series    = {IRCDL},
  file      = {:own-pdf/Zerhoudi2022a_ircdl_simulating-user-behavior_preprint.pdf:PDF},
}

@Article{Paalvast2022_aim_radiology-report-generation,
  author   = {Olivier Paalvast and Meike Nauta and Marion Koelle and Jeroen Geerdink and Onno Vijlbrief and Johannes H. Hegeman and Christin Seifert},
  journal  = {Artificial Intelligence in Medicine},
  title    = {Radiology report generation for proximal femur fractures using deep classification and language generation models},
  year     = {2022},
  issn     = {0933-3657},
  pages    = {102281},
  volume   = {128},
  abstract = {Proximal femur fractures represent a major health concern, and substantially contribute to the morbidity of elderly. Correct classification and diagnosis of hip fractures has a significant impact on mortality, costs and hospital stay. In this paper, we present a method and empirical validation for automatic subclassification of proximal femur fractures and Dutch radiological report generation that does not rely on manually curated data. The fracture classification model was trained on 11,000 X-ray images obtained from 5000 electronic health records in a general hospital. To generate the Dutch reports, we first trained an embedding model on 20,000 radiological reports of pelvic region fractures, and used its embeddings in the report generation model. We trained the report generation model on the 5000 radiological reports associated with the fracture cases. Our report generation model is on par with state-of-the-art in terms of BLEU and ROUGE scores. This is promising, because in contrast to those earlier works, our approach does not require manual preprocessing of either images or the reports. This boosts the applicability of automatic clinical report generation in practice. A quantitative and qualitative user study among medical students found no significant difference in provenance of real and generated reports. A qualitative, in-depth clinical relevance study with medical domain experts showed that from a human perspective the quality of the generated reports approximates the quality of the original reports and highlights challenges in creating sufficiently detailed and versatile training data for automatic radiology report generation.},
  doi      = {10.1016/j.artmed.2022.102281},
  file     = {:own-pdf/Paalvast2022_aim_radiology-report-generation_preprint.pdf:PDF},
  keywords = {Proximal femur fractures, Radiology report generation, Fracture classification, Radiology language model, User study},
  url      = {https://www.sciencedirect.com/science/article/pii/S093336572200046X},
}

@InProceedings{Nguyen2022_iclr-blog_pplmrevisiteds-mammoth,
  author    = {Nguyen, Van Bach and Trienes, Jan and Nauta, Meike and Pathak, Shreyasi and Youssef, Paul and Imangaliyev, Sultan and Schltterer, Jrg and Seifert, Christin},
  booktitle = {ICLR Blog Track},
  title     = {{PPLM Revisited: Steering and Beaming a Lumbering Mammoth to Control Text Generation}},
  year      = {2022},
  note      = {https://iclr-blog-track.github.io/2022/03/25/PPLM/},
  url       = {https://iclr-blog-track.github.io/2022/03/25/PPLM/},
}

@Article{Imangaliyev2022_diagnostics_stacking-for-microbiom-data,
  author         = {Imangaliyev, Sultan and Schltterer, Jrg and Meyer, Folker and Seifert, Christin},
  journal        = {Diagnostics},
  title          = {Diagnosis of Inflammatory Bowel Disease and Colorectal Cancer through Multi-View Stacked Generalization Applied on Gut Microbiome Data},
  year           = {2022},
  issn           = {2075-4418},
  number         = {10},
  volume         = {12},
  abstract       = {Most of the microbiome studies suggest that using ensemble models such as Random Forest results in best predictive power. In this study, we empirically evaluate a more powerful ensemble learning algorithm, multi-view stacked generalization, on pediatric inflammatory bowel disease and adult colorectal cancer patients&rsquo; cohorts. We aim to check whether stacking would lead to better results compared to using a single best machine learning algorithm. Stacking achieves the best test set Average Precision (AP) on inflammatory bowel disease dataset reaching AP = 0.69, outperforming both the best base classifier (AP = 0.61) and the baseline meta learner built on top of base classifiers (AP = 0.63). On colorectal cancer dataset, the stacked classifier also outperforms (AP = 0.81) both the best base classifier (AP = 0.79) and the baseline meta learner (AP = 0.75). Stacking achieves best predictive performance on test set outperforming the best classifiers on both patient cohorts. Application of the stacking solves the issue of choosing the most appropriate machine learning algorithm by automating the model selection procedure. Clinical application of such a model is not limited to diagnosis task only, but it also can be extended to biomarker selection thanks to feature selection procedure.},
  article-number = {2514},
  doi            = {10.3390/diagnostics12102514},
  file           = {:own-pdf/Imangaliyev2022_mdpi_stacking-for-microbiom_preprint.pdf:PDF},
  url            = {https://www.mdpi.com/2075-4418/12/10/2514},
}

@InProceedings{Zerhoudi2022_cikm_simiir20framework,
  author    = {Zerhoudi, Saber and G\"{u}nther, Sebastian and Plassmeier, Kim and Borst, Timo and Seifert, Christin and Hagen, Matthias and Granitzer, Michael},
  booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  title     = {{The SimIIR 2.0 Framework: User Types, Markov Model-Based Interaction Simulation, and Advanced Query Generation}},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {46614666},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '22},
  abstract  = {Simulated user retrieval system interactions enable studies with controlled user behavior. To this end, the SimIIR framework offers static, rule-based methods. We present an extended SimIIR 2.0 version with new components for dynamic user type-specific Markov model-based interactions and more realistic query generation. A flexible modularization ensures that the SimIIR 2.0 framework can serve as a platform to implement, combine, and run the growing number of proposed search behavior and query simulation ideas.},
  addendum  = {\textit{Best Paper Award (Resource Paper Track)}},
  doi       = {10.1145/3511808.3557711},
  file      = {:own-pdf/Zerhoudi2022b_cikm_simiir20-framework_preprint.pdf:PDF},
  isbn      = {9781450392365},
  keywords  = {simulation, search behavior, software framework, user modeling},
  location  = {Atlanta, GA, USA},
  numpages  = {6},
}

@InProceedings{Trienes2022_tsar_patient-friendly-clinical-notes,
  author    = {Jan Trienes and J\"{o}rg Schl\"{o}tterer and Hans-Ulrich Schildhaus and Christin Seifert},
  booktitle = {Proc. EMNLP Workshop on Text Simplification, Accessibility, and Readability (TSAR)},
  title     = {Patient-friendly Clinical Notes: Towards a new Text Simplification Dataset},
  year      = {2022},
  file      = {:own-pdf/Trienes2022_tsar_patient-friendly-clinical-notes_preprint.pdf:PDF},
  url       = {https://aclanthology.org/2022.tsar-1.3/},
}

@InProceedings{Youssef2022_dmbih_model-personalizaton-patient-data,
  author    = {Paul Youssef and J\"{o}rg Schl\"{o}tterer and Sultan Imangaliyev and Christin Seifert},
  booktitle = {Proc. ICDM Workshop on Data Mining in Biomedical Informatics and Healthcare (DMBIH)},
  title     = {Model Personalization with Static and Dynamic Patients Data},
  year      = {2022},
  doi       = {10.1109/ICDMW58026.2022.00051},
  file      = {:own-pdf/Youssef2022_dmbih_model-personalizaton-patient-data_preprint.pdf:PDF},
}

@Article{Lu2022_tsnre_channel-contribution-sleep-scoring,
  author  = {Lu, Changqing and Pathak, Shreyasi and Englebienne, Gwenn and Seifert, Christin},
  journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  title   = {Channel Contribution In Deep Learning Based Automatic Sleep Scoring  How Many Channels Do We Need?},
  year    = {2022},
  pages   = {494-505},
  volume  = {31},
  doi     = {10.1109/TNSRE.2022.3227040},
  file    = {:own-pdf/Lu2022_tsnre_channel-contribution-sleep-scoring_preprint.pdf:PDF},
}

@Article{Nauta2023_csur_evaluating-xai-survey,
  author    = {Nauta, Meike and Trienes, Jan and Pathak, Shreyasi and Nguyen, Elisa and Peters, Michelle and Schmitt, Yasmin and Schl\"{o}tterer, J\"{o}rg and van Keulen, Maurice and Seifert, Christin},
  journal   = {ACM Comput. Surv.},
  title     = {From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI},
  year      = {2023},
  issn      = {0360-0300},
  month     = {feb},
  abstract  = {The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the last 7 years at major AI and ML conferences that introduce an XAI method. We find that 1 in 3 papers evaluate exclusively with anecdotal evidence, and 1 in 5 papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training in order to optimize for accuracy and interpretability simultaneously.},
  address   = {New York, NY, USA},
  comment   = {https://utwente-dmb.github.io/xai-papers/},
  doi       = {10.1145/3583558},
  file      = {:own-pdf/Nauta2023_csur_evaluating-xai-survey_preprint-incl-suppl.pdf:PDF},
  keywords  = {explainability, explainable AI, explainable artificial intelligence, XAI, interpretable machine learning, interpretability, quantitative evaluation methods, evaluation},
  publisher = {Association for Computing Machinery},
}

@InProceedings{Nauta2023_cvpr_pipnet,
  author    = {Meike Nauta and J\"{o}rg Schl\"{o}tterer and Maurice van Keulen and Christin Seifert},
  booktitle = {{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}},
  title     = {PIP-Net: Patch-Based Intuitive Prototypes for Interpretable Image Classification},
  year      = {2023},
  file      = {:own-pdf/Nauta2023_cvpr_pipnet.pdf:PDF},
}

@Article{Rietberg2023_mdpi_classifying-ms-patient-reports,
  author         = {Rietberg, Max Tigo and Nguyen, Van Bach and Geerdink, Jeroen and Vijlbrief, Onno and Seifert, Christin},
  journal        = {Diagnostics},
  title          = {Accurate and Reliable Classification of Unstructured Reports on Their Diagnostic Goal Using BERT Models},
  year           = {2023},
  issn           = {2075-4418},
  number         = {7},
  volume         = {13},
  abstract       = {Understanding the diagnostic goal of medical reports is valuable information for understanding patient flows. This work focuses on extracting the reason for taking an MRI scan of Multiple Sclerosis (MS) patients using the attached free-form reports: Diagnosis, Progression or Monitoring. We investigate the performance of domain-dependent and general state-of-the-art language models and their alignment with domain expertise. To this end, eXplainable Artificial Intelligence (XAI) techniques are used to acquire insight into the inner workings of the model, which are verified on their trustworthiness. The verified XAI explanations are then compared with explanations from a domain expert, to indirectly determine the reliability of the model. BERTje, a Dutch Bidirectional Encoder Representations from Transformers (BERT) model, outperforms RobBERT and MedRoBERTa.nl in both accuracy and reliability. The latter model (MedRoBERTa.nl) is a domain-specific model, while BERTje is a generic model, showing that domain-specific models are not always superior. Our validation of BERTje in a small prospective study shows promising results for the potential uptake of the model in a practical setting.},
  article-number = {1251},
  doi            = {10.3390/diagnostics13071251},
  file           = {:own-pdf/Rietberg2023_mdpi_classifying-ms-patient-reports_preprint.pdf:PDF},
  url            = {https://www.mdpi.com/2075-4418/13/7/1251},
}

@Article{Borys2023_ejr_xai-in-medical-saliency,
  author   = {Katarzyna Borys and Yasmin {Alyssa Schmitt} and Meike Nauta and Christin Seifert and Nicole Krmer and Christoph M. Friedrich and Felix Nensa},
  journal  = {European Journal of Radiology},
  title    = {Explainable AI in Medical Imaging: An overview for clinical practitioners  Saliency-based XAI approaches},
  year     = {2023},
  issn     = {0720-048X},
  pages    = {110787},
  abstract = {Since recent achievements of Artificial Intelligence (AI) have proven significant success and promising results throughout many fields of application during the last decade, AI has also become an essential part of medical research. The improving data availability, coupled with advances in high-performance computing and innovative algorithms, has increased AI's potential in various aspects. Because AI rapidly reshapes research and promotes the development of personalized clinical care, alongside its implementation arises an urgent need for a deep understanding of its inner workings, especially in high-stake domains. However, such systems can be highly complex and opaque, limiting the possibility of an immediate understanding of the systems decisions. Regarding the medical field, a high impact is attributed to these decisions as physicians and patients can only fully trust AI systems when reasonably communicating the origin of their results, simultaneously enabling the identification of errors and biases. Explainable AI (XAI), becoming an increasingly important field of research in recent years, promotes the formulation of explainability methods and provides a rationale allowing users to comprehend the results generated by AI systems. In this paper, we investigate the application of XAI in medical imaging, addressing a broad audience, especially healthcare professionals. The content focuses on definitions and taxonomies, standard methods and approaches, advantages, limitations, and examples representing the current state of research regarding XAI in medical imaging. This paper focuses on saliency-based XAI methods, where the explanation can be provided directly on the input data (image) and which naturally are of special importance in medical imaging.},
  doi      = {10.1016/j.ejrad.2023.110787},
  file     = {:own-pdf/Borys2023_ejr_xai-in-medical-saliency_preprint.pdf:PDF},
  keywords = {Explainable AI, Medical Imaging, Radiology, Black-Box, Explainability, Interpretability},
  url      = {https://www.sciencedirect.com/science/article/pii/S0720048X23001018},
}

@Article{Borys2023_ejr_xai-in-medical-beyond-saliency,
  author   = {Katarzyna Borys and Yasmin Alyssa Schmitt and Meike Nauta and Christin Seifert and Nicole Krmer and Christoph M. Friedrich and Felix Nensa},
  journal  = {European Journal of Radiology},
  title    = {Explainable AI in medical imaging: An overview for clinical practitioners  Beyond saliency-based XAI approaches},
  year     = {2023},
  issn     = {0720-048X},
  pages    = {110786},
  volume   = {162},
  abstract = {Driven by recent advances in Artificial Intelligence (AI) and Computer Vision (CV), the implementation of AI systems in the medical domain increased correspondingly. This is especially true for the domain of medical imaging, in which the incorporation of AI aids several imaging-based tasks such as classification, segmentation, and registration. Moreover, AI reshapes medical research and contributes to the development of personalized clinical care. Consequently, alongside its extended implementation arises the need for an extensive understanding of AI systems and their inner workings, potentials, and limitations which the field of eXplainable AI (XAI) aims at. Because medical imaging is mainly associated with visual tasks, most explainability approaches incorporate saliency-based XAI methods. In contrast to that, in this article we would like to investigate the full potential of XAI methods in the field of medical imaging by specifically focusing on XAI techniques not relying on saliency, and providing diversified examples. We dedicate our investigation to a broad audience, but particularly healthcare professionals. Moreover, this work aims at establishing a common ground for cross-disciplinary understanding and exchange across disciplines between Deep Learning (DL) builders and healthcare professionals, which is why we aimed for a non-technical overview. Presented XAI methods are divided by a methods output representation into the following categories: Case-based explanations, textual explanations, and auxiliary explanations.},
  doi      = {10.1016/j.ejrad.2023.110786},
  file     = {:own-pdf/Borys2023_ejr_xai-in-medical-beyond-saliency_publisher.pdf:PDF},
  keywords = {Explainable AI, Medical imaging, Radiology, Black-Box, Explainability, Interpretability},
  url      = {https://www.sciencedirect.com/science/article/pii/S0720048X23001006},
}

@Booklet{RTGMeeting2023-report,
  title     = {Proceedings of the 2023 Joint Workshop of the German Research Training Groups in Computer Science},
  author    = {{:None}},
  year      = {2023},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.17185/DUEPUBLICO/78280},
  editor    = {Helmut Seidl and Christin Seifert},
  keywords  = {004},
  language  = {en},
  publisher = {DuEPublico: Duisburg-Essen Publications online, University of Duisburg-Essen, Germany},
  url       = {https://duepublico2.uni-due.de/receive/duepublico_mods_00078280},
}

@InProceedings{Papenmeier2023_dis_user-perception-abstaining,
  author    = {Papenmeier, Andrea and Hienert, Daniel and Kammerer, Yvonne and Seifert, Christin and Kern, Dagmar},
  booktitle = {Companion Publication of the 2023 ACM Designing Interactive Systems Conference},
  title     = {Know What Not To Know: Users Perception of Abstaining Classifiers},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {169172},
  publisher = {Association for Computing Machinery},
  series    = {DIS '23 Companion},
  abstract  = {Machine learning systems can help humans to make decisions by providing decision suggestions (i.e., a label for a datapoint). However, individual datapoints do not always provide enough clear evidence to make confident suggestions. Although methods exist that enable systems to identify those datapoints and subsequently abstain from suggesting a label, it remains unclear how users would react to such system behavior. This paper presents first findings from a user study on systems that do or do not abstain from labeling ambiguous datapoints. Our results show that label suggestions on ambiguous datapoints bear a high risk of unconsciously influencing the users decisions, even toward incorrect ones. Furthermore, participants perceived a system that abstains from labeling uncertain datapoints as equally competent and trustworthy as a system that delivers label suggestions for all datapoints. Consequently, if abstaining does not impair a systems credibility, it can be a useful mechanism to increase decision quality.},
  doi       = {10.1145/3563703.3596622},
  file      = {:/Volumes/Data/data-work/Research/Literature/own-pdf/Papenmeier2023_dis_user-perception-abstaining_preprint.pdf:PDF},
  isbn      = {9781450398985},
  keywords  = {Perception, Human-Centered Machine Learning, Abstaining},
  location  = {Pittsburgh, PA, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1145/3563703.3596622},
}

@Article{Bauer2023_sigirforum_dagstuhl-report-frontiers-ir,
  author     = {Christine Bauer and Ben Cartarette and Nicola Ferro and Norbert Fuhr and Joeran Beel and Timo Breuer and Charles L. A. Clarke and Anita Crescenzi and Gianluca Demartini and Giorgio Maria Di Nunzio and Laura Dietz and Guglielmo Faggioli and Bruce Ferwerda and Maik Fr\"{o}be and Matthias Hagen and Allan Hanbury and Claudia Hauff and Dietmar Jannach and Noriko Kando and Evangelos Kanoulas and Bart P. Knijnenburg and Udo Kruschwitz and Meijie Li and Maria Maistro and Lien Michiels and Andrea Papenmeier and Martin Potthast and Paolo Rosso and Alan Said and Philipp Schaer and Christin Seifert and Damiano Spina and Benno Stein and Nava Tintarev and Julian Urbano and Henning Wachsmuth and Martijn C. Willemsen and Justin Zobel},
  journal    = {SIGIR Forum},
  title      = {Report on the Dagstuhl Seminar on Frontiers of Information Access Experimentation for Research and Education},
  year       = {2023},
  month      = jun,
  number     = {1},
  volume     = {57},
  address    = {New York, NY, USA},
  comment    = {not peer-reviewed},
  file       = {:own-pdf/Bauer2023_sigirforum_dagstuhl-report-frontiers-ir_publisher.pdf:PDF},
  issue_date = {June 2023},
  publisher  = {Association for Computing Machinery},
  url        = {https://sigir.org/wp-content/uploads/2023/07/p07.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
